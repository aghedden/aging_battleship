---
title: "cleaned_R_aging_battleship_analyses"
output: html_document
date: "2024-08-01"
---

# Load in Data and Required Packages
```{r setup, include=TRUE} 
knitr::opts_chunk$set(echo = TRUE)

# set mirror for cran to allow for knitting
r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)

# install and call required packages 
# if (!require("package")) {install.packages("package"); require("package")}
if (!require("dplyr")) {install.packages("dplyr"); require("dplyr")}
if (!require("knitr")) {install.packages("knitr"); require("knitr")} 
if (!require("lme4")) {install.packages("lme4"); require("lme4")}
if (!require("lmerTest")) {install.packages('lmerTest'); require("lmerTest")}
if (!require("ggplot2")) {install.packages("ggplot2"); require("ggplot2")} 


if (!require("readr")) {install.packages("readr"); require("readr")}
if (!require("tidyverse")) {install.packages("tidyverse"); require("tidyverse")}
if (!require("tidytext")) {install.packages("tidytext"); require("tidytext")}
if (!require("textdata")) {install.packages("textdata"); require("textdata")}
if (!require("stringr")) {install.packages("stringr"); require("stringr")}
if (!require("wordcloud2")) {install.packages("wordcloud2"); require("wordcloud2")} 
if (!require("wordcloud")) {install.packages("wordcloud"); require("wordcloud")} 
if (!require("RColorBrewer")) {install.packages("RColorBrewer"); require("RColorBrewer")} 
if (!require("data.table")) {install.packages("data.table"); require("data.table")} 
if (!require("changepoint")) {install.packages("changepoint"); require("changepoint")} 
if (!require("tibble")) {install.packages("tibble"); require("tibble")} 
if (!require("EntropyExplorer")) {install.packages("EntropyExplorer"); require("EntropyExplorer")} 
if (!require("entropy")) {install.packages("entropy"); require("entropy")} 
if (!require("sjPlot")) {install.packages('sjPlot'); require("sjPlot")}
if (!require("see")) {install.packages('see'); require("see")}
if (!require("brms")) {install.packages('brms'); require("brms")}
if (!require("devtools")) {install.packages("devtools"); require("devtools")}
if (!require("ggpubr")) {install.packages('ggpubr'); require("ggpubr")}
if (!require("dlookr")) {install.packages('dlookr'); require("dlookr")}
if (!require("cowplot")) {install.packages('cowplot'); require("cowplot")}
if (!require("gridGraphics")) {install.packages('gridGraphics'); require("gridGraphics")}
if (!require("ggeffects")) {install.packages('ggeffects'); require("ggeffects")}
if (!require("ggpubr")) {install.packages('ggpubr'); require("ggpubr")}
if (!require("robustlmm")) {install.packages('robustlmm'); require("robustlmm")}
if (!require("MASS")) {install.packages('MASS'); require("MASS")}
```

# Load in Data
```{r}
# data for the information and reward mixed effects model:
info_rew_mixed_eff_data <- read.csv("~/Library/CloudStorage/Box-Box/Bakkour-Lab/projects/Battleship_task/analysis/dataframes/info_rew_mixed_eff_data.csv")

# data with Euclidean choice distance calculations
cart_dist_ent_df <- read.csv("~/Library/CloudStorage/Box-Box/Bakkour-Lab/projects/Battleship_task/analysis/dataframes/cart_dist_ent_df.csv")

# dataframe with forager scores, information and reward values, and changepoint for each participant
forscore_cpt_data <- read.csv("~/Library/CloudStorage/Box-Box/Bakkour-Lab/projects/Battleship_task/analysis/dataframes/forscore_cpt_data.csv")
  # excluded participants who did not get a forager score/changepoint
    # YA 18, 32, 49, 55
    # MA 10, 26, 41, 45
    # OA 8, 9, 11, 22, 29, 33, 40
    # 15 participants total excluded from this df and corresponding analyses

# df containing maximum scores earned by participants and total trials completed in the task
merged_scores_df <- read.csv('~/Library/CloudStorage/Box-Box/Bakkour-Lab/projects/Battleship_task/analysis/dataframes/merged_scores_df.csv')

# totals df: summary table of multiple task completion stats from mousetracking data
totals_df <- read.csv('~/Library/CloudStorage/Box-Box/Bakkour-Lab/projects/Battleship_task/analysis/dataframes/totals_df.csv')
  # can also serve as a lookup table for later analyses that required obtaining the cpt or age of participants
  # summary output of mousetracking data cleaning and wrangling. see `aging_bship_mousetracking_wrangling.ipynb`

# genders df: contains gender info for participants
genders_df <- read.csv("~/Library/CloudStorage/Box-Box/Bakkour-Lab/projects/Battleship_task/analysis/dataframes/bship_genders.csv")

# data with all mean directed exploration types calculated
mean_expl_df <- read.csv("~/Library/CloudStorage/Box-Box/Bakkour-Lab/projects/Battleship_task/analysis/mean_expl_df.csv")
```

## Create Vectors for Subject Variables
```{r}
# create subject IDs
subject_ids <- c('YA01','YA02','YA03','YA04','YA05','YA06','YA07','YA08','YA09','YA10','YA11','YA12','YA13','YA14','YA15','YA16','YA17','YA18','YA19','YA20','YA21','YA22','YA23','YA24','YA25','YA26','YA27','YA28','YA29','YA30','YA31','YA32','YA33','YA34','YA35','YA36','YA37','YA38','YA39','YA40','YA41','YA42','YA43','YA44','YA45','YA46','YA47','YA48','YA49','YA50','YA51','YA52','YA53','YA54','YA55','YA56','YA57','MA01','MA02','MA03','MA04','MA05','MA06','MA07','MA08','MA09','MA10','MA11','MA12','MA13','MA14','MA15','MA16','MA17','MA18','MA19','MA20','MA21','MA22','MA23','MA24','MA25','MA26','MA27','MA28','MA29','MA30','MA31','MA32','MA33','MA34','MA35','MA36','MA37','MA38','MA39','MA40','MA41','MA42','MA43','MA44','MA45','MA46','MA47','MA48','MA49','MA50','MA51','MA52','MA53','MA54','MA55','MA56','MA57','MA58','MA59','OA01','OA02','OA03','OA04','OA05','OA06','OA07','OA08','OA09','OA10','OA11','OA12','OA13','OA14','OA15','OA16','OA17','OA18','OA19','OA20','OA21','OA22','OA23','OA24','OA25','OA26','OA27','OA28','OA29','OA30','OA31','OA32','OA33','OA34','OA35','OA36','OA37','OA38','OA39','OA40','OA41','OA42','OA43','OA44','OA45','OA46','OA47','OA48','OA49','OA50','OA51','OA52','OA53')

# create age vector 
ages <- c(20,19,19,18,20,22,21,20,19,19,20,19,20,24,20,19,21,19,21,19,20,22,20,19,20,26,19,19,18,20,20,19,21,20,18,19,20,20,22,20,20,21,22,19,19,21,19,19,20,20,20,20,21,20,20,21,21,44,42,42,48,35,45,39,39,39,37,40,38,38,40,39,39,43,37,46,36,39,42,45,38,35,38,38,47,37,40,41,43,48,40,41,43,36,43,43,48,43,42,38,38,48,43,38,37,40,43,36,47,44,46,39,40,45,37,39,54,64,51,53,71,58,55,52,52,57,51,55,52,60,62,56,56,60,57,59,63,64,61,57,59,56,56,56,59,52,56,71,55,64,50,54,56,53,65,70,54,51,66,54,50,51,57,53,56,51,52,57,51)

# create CPT vector 
cpts <- c(84,33,49,67,39,66,36,68,64,11,58,36,81,24,31,26,77,0,65,84,49,24,21,51,72,12,69,60,58,24,51,0,76,22,58,36,72,52,59,53,55,22,62,30,44,51,42,9,0,66,27,67,38,40,3,49,33,51,80,29,13,43,83,35,58,55,0,31,43,33,33,41,37,11,57,34,56,63,12,13,35,60,0,58,15,11,31,33,36,31,64,29,36,46,36,55,39,0,37,8,77,0,46,55,22,67,29,53,30,16,28,38,23,33,74,50,82,26,25,64,52,26,40,0,2,17,0,60,53,25,5,44,16,50,15,24,13,0,21,32,23,16,59,48,0,63,56,45,0,62,7,53,70,57,31,0,15,30,30,44,51,68,48,73,44,76,67,35,36)

# create named vectors (equivalent to Python dicts)
subject_age_dict <- setNames(ages, subject_ids)
subject_cpt_dict <- setNames(cpts, subject_ids)
```

# General Task Completion Analyses
This set of analyses examines general task completion variables, such as total trials completed and points earned, for example. We employed a variety of OLS linear regressions to investigate how these factors changed with age.

## Total Score and Age
Run a linear regression to regress the number of points earned, the **total score**, in session against **age** of the participant.

**Parameters:**

* `max_score`: The final score of the participant in the task
* `age`: The age of the participant

**Results:**
* As our participants’ age increases,  they earn fewer points overall by the end of the task (β = -0.961, 95% CI [-1.723, -0.200], p = 0.01).
* Older age is associated with lower overall scores.
```{r}
age_score_mod <- lm(max_score ~ age, data = merged_scores_df)
summary(age_score_mod)
confint(age_score_mod)
```


## Age and Likelihood of Detecting a Changepoint in the Changepoint Detection Test
The changepoint detection test failed to detect a changepoint for 13 of 169 (~8%) participants. Run a logistic regression to predict **failed_cpt** from the **age** of the participant.
 
**Parameters:**
* `failed_cpt`: Whether participant failed the cpt detection test (i.e., cpt = 0). 0 = did not fail, 1 = failed
* `age`: The age of the participant

A logistic model indicated no significant relationship between age and the likelihood of detecting a changepoint (odds ratio (OR) = 1.025, 95% CI [-0.013,  0.065], p = 0.199), and these participants were excluded from the remaining analyses.
```{r}
# make data frame with one row per participant
fail_cpt_df <- data.frame(subject_id = names(subject_age_dict))
fail_cpt_df$age <- subject_age_dict[fail_cpt_df$subject_id]
fail_cpt_df$cpt <- subject_cpt_dict[fail_cpt_df$subject_id]
# create binary failed_cpt column (1 = failed if cpt == 0)
fail_cpt_df$failed_cpt <- ifelse(fail_cpt_df$cpt == 0, 1, 0)

# verify
cat("num failed:", sum(fail_cpt_df$failed_cpt == 1), "\n")
print(fail_cpt_df[fail_cpt_df$failed_cpt == 1, ])

# logistic regression: failed_cpt ~ age
fail_cpt_model <- glm(failed_cpt ~ age, data = fail_cpt_df, family = binomial)
summary(fail_cpt_model)

# odds ratios
exp(coef(fail_cpt_model))

confint(fail_cpt_model)
```

## Age and Learning Speed (i.e., final changepoint)
Run a linear regression to regress **changepoint** against **age** of the participant.

**Parameters:**
* `changepoint`: The trial number at which the changepoint detection test detected learning of the shape set. Lower changepoint indicates a sooner trial and thus indicates faster learning.
* `age`: The age of the participant
        
**Results:**
* With increasing age, the final changepoint trial occurs earlier (β = -0.267, 95% CI [-0.471, -0.064], p = 0.01)
* Older adults learn the shapes more quickly
```{r}
age_cpt_mod <- lm(changepoint ~ age, data = forscore_cpt_data)
summary(age_cpt_mod)
confint(age_cpt_mod)
```


## Total Trials Completed and Age
Run a linear regression to regress **total trials** in session against **age** of the participant.

**Parameters:**
* `tot_trials`: The total number of trials completed by the participant during the task
* `age`: The age of the participant

**Results:**
* As age increased, the number of trials completed in the task decreased (β = -0.199, 95% CI [-0.365, -0.035], p = 0.018)
* Older age is associated with completing fewer trials
```{r}
age_trial_corr_model <- lm(tot_trials ~ age, data = totals_df)
summary(age_trial_corr_model)
confint(age_trial_corr_model)
```


## Total Choices Made and Age
Run a linear regression to regress **total choices** in session against **age** of the participant.

**Parameters:**
* `tot_choices`: The **total** number of choices made by the participant in the task
* `age`: The age of the participant

**Results:**
* There was no relationship between the total number of choices made in the task and age
* Older age is not associated with more choices overall
```{r}
age_tot_choice_model <- lm(tot_choices ~ age, data = totals_df)
summary(age_tot_choice_model)
confint(age_trial_corr_model)
```


## Total Choices per Trial and Age
Run a linear regression to regress the **average choices** made against **age** of the participant.

**Parameters:**
* `avg_choices`: The average number of choices per trial for a given participant
* `age`: The age of the participant

**Results:**
* There is a positive relationship between the average number of choices per trial and age
* Older age is associated with making more choices per trial (β = 0.030, 95% CI [0.017, 0.044], p < 0.001).
```{r}
age_avg_choice_model <- lm(avg_choices ~ age, data = totals_df)
summary(age_avg_choice_model)
confint(age_avg_choice_model)
```

## Average Information per Trial and Age
Run a linear regression to regress the **average amount of information per trial** against **age** of the participant

**Parameters:**
* `t_prop_tot_info`: The average amount of information gain per trial for a given participant
* `age`: The age of the participant

**Results:**
* As age increased, the average amount of information per trial increased (β = 0.023, 95% CI [0.012, 0.033], p < 0.001).
* Older age is associated with gaining more information per trial
```{r}
age_avg_info_model <- lm(t_prop_tot_info ~ age, data = totals_df)
summary(age_avg_info_model)
confint(age_avg_info_model)
```

# Choice Distance Mixed Effects Model
Investigate the effect of age, choice number, and trial number on pairwise choice distance. 

Run a mixed-effects linear regression to regress **choice distance** between each pair of choices in trial against **age** of the participant, **choice number** in trial, and **trial number** in session. Also, test for all possible interactions. Include intercepts for subjects for random effects. 

**Parameters:**
* `choice_dist`: The choice number in a given trial, where a choice is a selection of a tile on the grid
* `age`: The age of the participant
* `choice_num`: The choice number in a given trial, where a choice is a selection of a tile on the grid
* `trial_num`: The trial number at which a choice was made
* `subject_id`: The unique Subject ID for each participant

**Results:**
* As age increased, the distance between pairs of choices also increased
* The distance between choices grew as trials progressed 
* Significant interactions between the following:
  + Age and choice number
  + Age and trial number
  + Choice number and trial number
* A three-way interaction between age, choice number, and trial number reveals that the effect of choice number and trial number on choice distance is weaker in older adults
```{r}
choice_dist_mix_mod <- lmerTest::lmer(choice_dist ~ age*choice_num*trial_num + (1|subject_id), data=cart_dist_ent_df) 
summary(choice_dist_mix_mod)
confint(choice_dist_mix_mod)
```

## Choice Distance Plot
### Bin data and find average points to plot 
```{r}
# bin the data and find the average points to plot

# bin by age
young_bin_df2 <- cart_dist_ent_df[cart_dist_ent_df$age <= 33,]
old_bin_df2 <- cart_dist_ent_df[cart_dist_ent_df$age >= 56,]


# within each age bin, bin by trial (3 bins, early middle and late)
young_bin_df2 <- young_bin_df2 %>%
  group_by(subject_id) %>% # perform the next functions by unique Subject
  mutate(trial_bin_ranges = cut(trial_num, breaks=3)) %>% # create bins (by subject) for trial numbers; will result in a bin range unique to a subject; only leaving this in here as a sanity check to make sure it is going by unique subject id
  mutate(trial_bins = as.numeric(cut(trial_num, breaks=3))) # create a column with the bin ranges replaced with bin number 1, 2, or 3

old_bin_df2 <- old_bin_df2 %>%
  group_by(subject_id) %>% # perform the next functions by unique Subject
  mutate(trial_bin_ranges = cut(trial_num, breaks=3)) %>% # create bins (by subject) for trial numbers; will result in a bin range unique to a subject; only leaving this in here as a sanity check to make sure it is going by unique subject id
  mutate(trial_bins = as.numeric(cut(trial_num, breaks=3))) # create a column with the bin ranges replaced with bin number 1, 2, or 3


# within each trial bin, bin by choice number (5 equal-sized bins)
# Rank choice number values
young_bin_df2 <- young_bin_df2 %>%
  group_by(subject_id, trial_bins) %>% # perform the next functions by unique Subject AND trial_bin
  mutate(choice_num_ranked = rank(choice_num)) # rank the choice number values for each subject trial bin - by - trial bin
num_bins <- 5
young_bin_df2 <- young_bin_df2 %>%
  mutate(choice_num_bins = cut(choice_num_ranked, breaks = seq(0, max(choice_num_ranked), length.out = num_bins + 1), labels = FALSE, include.lowest = TRUE))

old_bin_df2 <- old_bin_df2 %>%
  group_by(subject_id, trial_bins) %>% # perform the next functions by unique Subject AND trial_bin
  mutate(choice_num_ranked = rank(choice_num)) # rank the choice number values for each subject trial bin - by - trial bin
num_bins <- 5
old_bin_df2 <- old_bin_df2 %>%
  mutate(choice_num_bins = cut(choice_num_ranked, breaks = seq(0, max(choice_num_ranked), length.out = num_bins + 1), labels = FALSE, include.lowest = TRUE))


# Find the x- (choice number) and y-values (choice distance) for each subject in each choice number bin, in each trial bin

# Choice Number Coordinates: Make new table that holds all x- (choice number) and y-values (choice distance) per bin per subject; for each choice number bin within each trial bin, each subject should therefore end up with 15 x-y coordinates, one for each choice number bin in each trial bin

# YOUNG
tmp_young_cn_bin <- data.frame(matrix(ncol = 5, nrow = 1)) # create temp df to hold data and bind to main df in for loop below
colnames(tmp_young_cn_bin) <- c('subject_id', 'trial_bin', 'choice_num_bin', 'X_cn', 'Y_c_dist') # provide column names
young_cdist_bin_coordinates <- data.frame() # create new data frame for YA bin coordinate values; should be 855 rows (check)

for(s in unique(young_bin_df2$subject_id)){ 
  for(t in unique(young_bin_df2$trial_bins)){  
    for(c in unique(young_bin_df2$choice_num_bins)){  
      tmp_young_cn_bin$subject_id = s 
      tmp_young_cn_bin$trial_bin = t
      tmp_young_cn_bin$choice_num_bin = c 
      subset_data <- subset(young_bin_df2, subject_id == s & trial_bins == t & choice_num_bins == c) 
      tmp_young_cn_bin$X_cn = mean(subset_data$choice_num, na.rm=TRUE) 
      tmp_young_cn_bin$Y_c_dist = mean(subset_data$choice_dist, na.rm=TRUE) 
      young_cdist_bin_coordinates = rbind(young_cdist_bin_coordinates, tmp_young_cn_bin) 
    }
  }
}

# OLD
tmp_old_cn_bin <- data.frame(matrix(ncol = 5, nrow = 1)) # create temp df to hold data and bind to main df in for loop below
colnames(tmp_old_cn_bin) <- c('subject_id', 'trial_bin', 'choice_num_bin', 'X_cn', 'Y_c_dist') # provide column names
old_cdist_bin_coordinates <- data.frame() # create new data frame for YA bin coordinate values; should be 450 rows (check)

for(s in unique(old_bin_df2$subject_id)){ 
  for(t in unique(old_bin_df2$trial_bins)){  
    for(c in unique(old_bin_df2$choice_num_bins)){  
      tmp_old_cn_bin$subject_id = s 
      tmp_old_cn_bin$trial_bin = t
      tmp_old_cn_bin$choice_num_bin = c 
      subset_data <- subset(old_bin_df2, subject_id == s & trial_bins == t & choice_num_bins == c) 
      tmp_old_cn_bin$X_cn = mean(subset_data$choice_num, na.rm=TRUE) 
      tmp_old_cn_bin$Y_c_dist = mean(subset_data$choice_dist, na.rm=TRUE) 
      old_cdist_bin_coordinates = rbind(old_cdist_bin_coordinates, tmp_old_cn_bin) 
    }
  }
}


# NORMALIZE CHOICE NUMBER VALUES AND CHOICE DISTANCE VALUES
# we need to normalize our choice distance and choice number data in order to account for within-subject variability 
# removing between-subject variability in the error bars
# https://www.cogsci.nl/blog/tutorials/156-an-easy-way-to-create-graphs-with-within-subject-error-bars 
# to remove the between-subject variability, subtract the subject average from each observation, and add the grand average (i.e., the average of all the cells)

# find the "grand average" for choice distance and choice number 
young_cn_grand_average <- mean(young_bin_df2$choice_num, na.rm=TRUE) # 5.420612
young_cdist_grand_average <- mean(young_bin_df2$choice_dist, na.rm=TRUE) # 1.500176
# find the "grand average" for choice distance and choice number 
old_cn_grand_average <- mean(old_bin_df2$choice_num, na.rm=TRUE) # 6.04649
old_cdist_grand_average <- mean(old_bin_df2$choice_dist, na.rm=TRUE) # 1.613049

# find the average choice distance and choice number values for each subject
tmp_sub_cncd_avg <- data.frame(matrix(ncol = 3, nrow = 1)) # create temp df 
colnames(tmp_sub_cncd_avg) <- c('subject_id', 'avg_cn', 'avg_cdist') # provide column names
young_sub_cncd_avg <- data.frame() # create new data frame for young bin value averages
for(s in unique(young_bin_df2$subject_id)){
  tmp_sub_cncd_avg$subject_id = s
  subset_data <- subset(young_bin_df2, subject_id == s)
  tmp_sub_cncd_avg$avg_cn = mean(subset_data$choice_num, na.rm = TRUE)
  tmp_sub_cncd_avg$avg_cdist = mean(subset_data$choice_dist, na.rm = TRUE)
  young_sub_cncd_avg = rbind(young_sub_cncd_avg, tmp_sub_cncd_avg)
}

tmp_sub_cncd_avg <- data.frame(matrix(ncol = 3, nrow = 1))  
colnames(tmp_sub_cncd_avg) <- c('subject_id', 'avg_cn', 'avg_cdist') 
old_sub_cncd_avg <- data.frame() 
for(s in unique(old_bin_df2$subject_id)){
  tmp_sub_cncd_avg$subject_id = s
  subset_data <- subset(old_bin_df2, subject_id == s)
  tmp_sub_cncd_avg$avg_cn = mean(subset_data$choice_num, na.rm = TRUE)
  tmp_sub_cncd_avg$avg_cdist = mean(subset_data$choice_dist, na.rm = TRUE)
  old_sub_cncd_avg = rbind(old_sub_cncd_avg, tmp_sub_cncd_avg)
}

# add subject averages to young_cdist_bin_coordinates df
# YOUNG
# choice number averages
young_cdist_bin_coordinates$avg_cn <- NA # make new column
for (i in 1:nrow(young_cdist_bin_coordinates)) {
  subject_value <- young_cdist_bin_coordinates$subject_id[i]
  matching_row <- young_sub_cncd_avg[young_sub_cncd_avg$subject_id == subject_value, ] 
  if (nrow(matching_row) > 0) { young_cdist_bin_coordinates
    young_cdist_bin_coordinates$avg_cn[i] <- matching_row$avg_cn
  }
}
# choice distance averages
young_cdist_bin_coordinates$avg_cdist <- NA # make new column
for (i in 1:nrow(young_cdist_bin_coordinates)) {
  subject_value <- young_cdist_bin_coordinates$subject_id[i]
  matching_row <- young_sub_cncd_avg[young_sub_cncd_avg$subject_id == subject_value, ] 
  if (nrow(matching_row) > 0) { young_cdist_bin_coordinates
    young_cdist_bin_coordinates$avg_cdist[i] <- matching_row$avg_cdist
  }
}

# OLD
# choice number averages
old_cdist_bin_coordinates$avg_cn <- NA # make new column
for (i in 1:nrow(old_cdist_bin_coordinates)) {
  subject_value <- old_cdist_bin_coordinates$subject_id[i]
  matching_row <- old_sub_cncd_avg[old_sub_cncd_avg$subject_id == subject_value, ] 
  if (nrow(matching_row) > 0) { old_cdist_bin_coordinates
    old_cdist_bin_coordinates$avg_cn[i] <- matching_row$avg_cn
  }
}
# choice distance averages
old_cdist_bin_coordinates$avg_cdist <- NA # make new column
for (i in 1:nrow(old_cdist_bin_coordinates)) {
  subject_value <- old_cdist_bin_coordinates$subject_id[i]
  matching_row <- old_sub_cncd_avg[old_sub_cncd_avg$subject_id == subject_value, ] 
  if (nrow(matching_row) > 0) { old_cdist_bin_coordinates
    old_cdist_bin_coordinates$avg_cdist[i] <- matching_row$avg_cdist
  }
}

## subtract subject average and add grand average, making a new column for the new normalized cdist and cn values 
young_cdist_bin_coordinates$norm_cn <- young_cdist_bin_coordinates$X_cn - young_cdist_bin_coordinates$avg_cn + young_cn_grand_average
young_cdist_bin_coordinates$norm_cdist <- young_cdist_bin_coordinates$Y_c_dist - young_cdist_bin_coordinates$avg_cdist + young_cdist_grand_average

old_cdist_bin_coordinates$norm_cn <- old_cdist_bin_coordinates$X_cn - old_cdist_bin_coordinates$avg_cn + old_cn_grand_average
old_cdist_bin_coordinates$norm_cdist <- old_cdist_bin_coordinates$Y_c_dist - old_cdist_bin_coordinates$avg_cdist + old_cdist_grand_average

#### now we have normalized coordinates for each participant within each of our bins; let's average that to find the coordinates that we will plot
# take all of the normalized coordinates, and average across subjects per cn bin within each trial bin, resulting in one df containing 15 sets of coordinates to be plotted as the average binned raw data
# YOUNG
tmp_avg_pts <- data.frame(matrix(ncol = 4, nrow = 1)) 
colnames(tmp_avg_pts) <- c('trial_bin', 'choice_num_bin', 'avg_X', 'avg_Y') 
young_avg_cdist_coordinates <- data.frame() 
for(t in unique(young_cdist_bin_coordinates$trial_bin)){
  for(c in unique(young_cdist_bin_coordinates$choice_num_bin)){
    tmp_avg_pts$trial_bin = t
    tmp_avg_pts$choice_num_bin = c
    subset_data <- subset(young_cdist_bin_coordinates, trial_bin == t & choice_num_bin == c)
    tmp_avg_pts$avg_X = mean(subset_data$norm_cn, na.rm = TRUE) 
    tmp_avg_pts$avg_Y = mean(subset_data$norm_cdist, na.rm = TRUE) 
    young_avg_cdist_coordinates = rbind(young_avg_cdist_coordinates, tmp_avg_pts)
  }
}

# OLD
tmp_avg_pts <- data.frame(matrix(ncol = 4, nrow = 1)) 
colnames(tmp_avg_pts) <- c('trial_bin', 'choice_num_bin', 'avg_X', 'avg_Y') 
old_avg_cdist_coordinates <- data.frame() 
for(t in unique(old_cdist_bin_coordinates$trial_bin)){
  for(c in unique(old_cdist_bin_coordinates$choice_num_bin)){
    tmp_avg_pts$trial_bin = t
    tmp_avg_pts$choice_num_bin = c
    subset_data <- subset(old_cdist_bin_coordinates, trial_bin == t & choice_num_bin == c)
    tmp_avg_pts$avg_X = mean(subset_data$norm_cn, na.rm = TRUE) 
    tmp_avg_pts$avg_Y = mean(subset_data$norm_cdist, na.rm = TRUE) 
    old_avg_cdist_coordinates = rbind(old_avg_cdist_coordinates, tmp_avg_pts)
  }
}
```

### Find marginal effect regression lines
```{r}
# transform trial columns into numeric class for mean calculations
young_bin_df2$trial_num <- as.numeric(young_bin_df2$trial_num)
old_bin_df2$trial_num <- as.numeric(old_bin_df2$trial_num)

# find average trials for each bin
# find the average trial number within each trial bin and make that the trial value when finding the marginal effects
# YOUNG
young_cdist_tbin1_mean <- mean(young_bin_df2$trial_num[young_bin_df2$trial_bins == 1], na.rm = TRUE)
young_cdist_tbin2_mean <- mean(young_bin_df2$trial_num[young_bin_df2$trial_bins == 2], na.rm = TRUE)
young_cdist_tbin3_mean <- mean(young_bin_df2$trial_num[young_bin_df2$trial_bins == 3], na.rm = TRUE)

# OLD
old_cdist_tbin1_mean <- mean(old_bin_df2$trial_num[old_bin_df2$trial_bins == 1], na.rm = TRUE)
old_cdist_tbin2_mean <- mean(old_bin_df2$trial_num[old_bin_df2$trial_bins == 2], na.rm = TRUE)
old_cdist_tbin3_mean <- mean(old_bin_df2$trial_num[old_bin_df2$trial_bins == 3], na.rm = TRUE)


# find marginal effects for each of the 6 lines
# YOUNG
young_cdist_meffects_t1 <- ggpredict(choice_dist_mix_mod, c("choice_num", "age[18:33]", "trial_num[young_cdist_tbin1_mean]"))
young_cdist_meffects_t2 <- ggpredict(choice_dist_mix_mod, c("choice_num", "age[18:33]", "trial_num[young_cdist_tbin2_mean]"))
young_cdist_meffects_t3 <- ggpredict(choice_dist_mix_mod, c("choice_num", "age[18:33]", "trial_num[young_cdist_tbin3_mean]"))

# OLD
old_cdist_meffects_t1 <- ggpredict(choice_dist_mix_mod, c("choice_num", "age[56:71]", "trial_num[old_cdist_tbin1_mean]"))
old_cdist_meffects_t2 <- ggpredict(choice_dist_mix_mod, c("choice_num", "age[56:71]", "trial_num[old_cdist_tbin2_mean]"))
old_cdist_meffects_t3 <- ggpredict(choice_dist_mix_mod, c("choice_num", "age[56:71]", "trial_num[old_cdist_tbin3_mean]"))
```

### Make young bin scatterplot
```{r}
# plot the average points per bin
young_avg_cdist_coordinates <- young_avg_cdist_coordinates %>% arrange(choice_num_bin)

# plot average coordinates for young adults 
## change default colors for the plots to match the model plot
colors <- c("#E41818", "#26BC32", "#2A8FFC")
factor_levels <- unique(young_avg_cdist_coordinates$trial_bin)
## make the plot
plot(young_avg_cdist_coordinates$avg_X, young_avg_cdist_coordinates$avg_Y, type = "n")
# connect points with lines
for (level in factor_levels) {
  subset_data <- young_avg_cdist_coordinates[young_avg_cdist_coordinates$trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

# using SE for error bars
# Loop through factor levels again to draw error bars
plot(young_avg_cdist_coordinates$avg_X, young_avg_cdist_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.5), ylim = c(-2,13))
# connect points with lines
for (level in factor_levels) {
  subset_data <- young_avg_cdist_coordinates[young_avg_cdist_coordinates$trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}
for (level in factor_levels) {
  subset_data <- young_avg_cdist_coordinates[young_avg_cdist_coordinates$trial_bin == level, ]
  # Calculate standard error of the mean
  se_values <- sd(subset_data$avg_Y) / sqrt(length(subset_data$avg_Y))

  # Draw error bars using arrows
  arrows(
    subset_data$avg_X,
    subset_data$avg_Y - se_values,
    subset_data$avg_X,
    subset_data$avg_Y + se_values,
    angle = 90, code = 3, length = 0.1, col = colors[level]
  )
}

young_cdist_raw_plot <- recordPlot()
```

### Make old bin scatterplot
```{r}
# plot the average points per bin
old_avg_cdist_coordinates <- old_avg_cdist_coordinates %>% arrange(choice_num_bin)

# plot average coordinates for young adults 
## change default colors for the plots to match the model plot
colors <- c("#E41818", "#26BC32", "#2A8FFC")
factor_levels <- unique(old_avg_cdist_coordinates$trial_bin)
## make the plot
plot(old_avg_cdist_coordinates$avg_X, old_avg_cdist_coordinates$avg_Y, type = "n")
# connect points with lines
for (level in factor_levels) {
  subset_data <- old_avg_cdist_coordinates[old_avg_cdist_coordinates$trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

# using SE for error bars
# Loop through factor levels again to draw error bars
plot(old_avg_cdist_coordinates$avg_X, old_avg_cdist_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.5), ylim = c(-2,13))
# connect points with lines
for (level in factor_levels) {
  subset_data <- old_avg_cdist_coordinates[old_avg_cdist_coordinates$trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}
for (level in factor_levels) {
  subset_data <- old_avg_cdist_coordinates[old_avg_cdist_coordinates$trial_bin == level, ]
  # Calculate standard error of the mean
  se_values <- sd(subset_data$avg_Y) / sqrt(length(subset_data$avg_Y))

  # Draw error bars using arrows
  arrows(
    subset_data$avg_X,
    subset_data$avg_Y - se_values,
    subset_data$avg_X,
    subset_data$avg_Y + se_values,
    angle = 90, code = 3, length = 0.1, col = colors[level]
  )
}
old_cdist_raw_plot <- recordPlot()
```

### Make combined plot
```{r}
# set theme for all plots 
set_theme(
  base = theme_classic()
)

# YOUNG
young_avg_cdist_coordinates$trial_bin <- as.factor(young_avg_cdist_coordinates$trial_bin)
young_cdist_comb_plot <- ggplot(young_avg_cdist_coordinates, aes(x = avg_X, y = avg_Y, color = factor(trial_bin))) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), guide = "legend", labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01) + # Adjust position if needed
  geom_smooth(data = young_cdist_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_cdist_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_cdist_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Young Age Bin") + # add title
  labs(subtitle = "Ages 18-33") +
  #xlim(0.43,11) +
  #xlim(2.035,11) +
  xlim(2.7,12.5) +
  ylim(1,2.25) +
  ylab("Choice Distance") + # add y-axis label
  xlab("Choice Number") + # add x-axis label
  theme(panel.grid.major = element_blank()) +  # Remove major grid lines
  theme(panel.grid.minor = element_blank()) +
  theme(axis.text = element_text(size = 14)) + 
  theme(axis.title = element_text(size = 16)) +
  theme(plot.subtitle = element_text(size = 16)) +
  theme(plot.title = element_text(size = 18)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5)) +
  theme(legend.text = element_text(size = 14)) +
  theme(plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines')) +
  theme(legend.position = "bottom") +
  theme(legend.justification = "center") +
  theme(legend.title= element_blank())
young_cdist_comb_plot  

old_avg_cdist_coordinates$trial_bin <- as.factor(old_avg_cdist_coordinates$trial_bin)
old_cdist_comb_plot <- ggplot(old_avg_cdist_coordinates, aes(x = avg_X, y = avg_Y, color = factor(trial_bin))) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), guide = "legend", labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01) + # Adjust position if needed
  geom_smooth(data = old_cdist_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_cdist_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_cdist_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Old Age Bin") + # add title
  labs(subtitle = "Ages 56-71") +
  #xlim(0.43,11) +
  #xlim(2.035,11) +
  xlim(2.7,12.5) +
  ylim(1,2.25) +
  ylab("Choice Distance") + # add y-axis label
  xlab("Choice Number") + # add x-axis label
  theme(panel.grid.major = element_blank()) +  # Remove major grid lines
  theme(panel.grid.minor = element_blank()) +
  theme(axis.text = element_text(size = 14)) + 
  theme(axis.title = element_text(size = 16)) +
  theme(plot.subtitle = element_text(size = 16)) +
  theme(plot.title = element_text(size = 18)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5)) +
  theme(legend.text = element_text(size = 14)) +
  theme(plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines')) +
  theme(legend.position = "bottom") +
  theme(legend.justification = "center") +
  theme(legend.title= element_blank())
old_cdist_comb_plot  

# combine the plots into 1
cdist_comb_plot <- ggarrange(young_cdist_comb_plot, old_cdist_comb_plot, ncol = 2, nrow = 1, common.legend = TRUE, legend = "bottom", labels = c("A", "B"), font.label = list(size = 16))
cdist_comb_plot
```

```{r}
# Load required packages
library(ggplot2)
library(ggpubr)

# YOUNG plot with modifications focusing only on what you need
young_cdist_comb_plot <- ggplot(young_avg_cdist_coordinates, aes(x = avg_X, y = avg_Y, color = factor(trial_bin))) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), 
                  guide = guide_legend(
                    override.aes = list(linewidth = 3),
                    keywidth = unit(2, "cm"),  # Increase width between legend items
                    byrow = TRUE              # Arrange legend items in a row
                  ),
                  labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01) + 
  geom_smooth(data = young_cdist_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_cdist_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_cdist_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Young Age Bin") + 
  labs(subtitle = "Ages 18-33") +
  xlim(2.7,12.5) +
  ylim(1,2.25) +
  ylab("Choice Distance") + 
  xlab("Choice Number") +
  
  # Add a simple axis break indicator in the bottom left
  annotate("text", x = 2.8, y = 1.03, label = "//", size = 5, angle = 45) +

  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text = element_text(size = 24), 
        axis.title = element_text(size = 26),
        plot.subtitle = element_text(size = 26, hjust = 0.5),
        plot.title = element_text(size = 28, hjust = 0.5),
        legend.text = element_text(size = 24),
        plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines'),
        legend.position = "bottom",
        legend.justification = "center",
        legend.title = element_blank(),
        # Remove white boxes from legend
        legend.key = element_blank(),
        # Add gray background to legend
        legend.background = element_rect(fill = "gray90"))

# OLD plot with same modifications
old_cdist_comb_plot <- ggplot(old_avg_cdist_coordinates, aes(x = avg_X, y = avg_Y, color = factor(trial_bin))) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), 
                  guide = guide_legend(
                    override.aes = list(linewidth = 3),
                    keywidth = unit(2, "cm"),  # Increase width between legend items
                    byrow = TRUE              # Arrange legend items in a row
                  ),
                  labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01) + 
  geom_smooth(data = old_cdist_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_cdist_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_cdist_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Old Age Bin") + 
  labs(subtitle = "Ages 56-71") +
  xlim(2.7,12.5) +
  ylim(1,2.25) +
  ylab("Choice Distance") + 
  xlab("Choice Number") +
  
  # Add a simple axis break indicator in the bottom left
  annotate("text", x = 2.49, y = 1.03, label = "//", size = 6, angle = 145) +
  
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text = element_text(size = 24), 
        axis.title = element_text(size = 26),
        plot.subtitle = element_text(size = 26, hjust = 0.5),
        plot.title = element_text(size = 28, hjust = 0.5),
        legend.text = element_text(size = 24),
        plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines'),
        legend.position = "bottom",
        legend.justification = "center",
        legend.title = element_blank(),
        # Remove white boxes from legend
        legend.key = element_blank(),
        # Add gray background to legend
        legend.background = element_rect(fill = "gray90"))

# Combine the plots with shared legend
cdist_comb_plot <- ggarrange(young_cdist_comb_plot, old_cdist_comb_plot, 
                           ncol = 2, nrow = 1, 
                           common.legend = TRUE, 
                           legend = "bottom", 
                           labels = c("A", "B"), 
                           font.label = list(size = 26))

# Display the combined plot
cdist_comb_plot
```
```{r}
# For both plots, add key.width to the guide_legend to increase spacing
# Update the scale_color_manual with key.width parameter

# For young_cdist_comb_plot:
scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), 
                  guide = guide_legend(
                    override.aes = list(linewidth = 3),
                    keywidth = unit(3, "cm"),  # Increase width between legend items
                    byrow = TRUE              # Arrange legend items in a row
                  ),
                  labels = c("Early Trials", "Middle Trials", "Late Trials"))

# For old_cdist_comb_plot:
scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), 
                  guide = guide_legend(
                    override.aes = list(linewidth = 3),
                    keywidth = unit(3, "cm"),  # Increase width between legend items
                    byrow = TRUE              # Arrange legend items in a row
                  ),
                  labels = c("Early Trials", "Middle Trials", "Late Trials"))

```

## Choice distance vs age plot
```{r}
ggplot(data = cart_dist_ent_df, mapping = aes(x = age, y = choice_dist)) +
  geom_point()

mean_choice_dist_df <- aggregate(
  cbind(choice_dist, age) ~ subject_id, 
  data = cart_dist_ent_df, 
  FUN = function(x) c(mean = mean(x, na.rm = TRUE))
)

plot(mean_choice_dist_df$age, mean_choice_dist_df$choice_dist)
model <- lm(choice_dist ~ age, data = mean_choice_dist_df)
abline(model, col = "red", lwd = 2) 
```


# Directed Exploration Analyses
Run a linear regression to regress **mean directed exploration** against **age** of the participant.

**Parameters:**
* `overall_dir_expl`: The mean weighted (by reward and information) directed exploration across trials
* `age`: The age of the participant
        
**Results:**
* Older age was associated with larger deviations from the expected distance, indicating more directed exploration (β = 8.136 ✕ 10-4, 95% CI [2.182 ✕ 10-4, 1.409 ✕ 10-3], p = 0.008).
```{r}
dir_expl_age_model <- lm(overall_dir_expl ~ age, data = mean_expl_df)
summary(dir_expl_age_model)
confint(dir_expl_age_model)
```

## Directed Exploration vs age plot
```{r}
direxpl_vs_age <- ggplot(mean_expl_df, aes(age, overall_dir_expl)) +
  geom_point(color = 'black') +   
  #scale_color_gradient(low = "#0B72F7", high = "#F70B0B") + # customized color palette
  stat_smooth(geom = "smooth",  method = "lm", color='#0B72F7') +
  #geom_function(fun=Vectorize(i_function), linewidth = 1) +
  labs(color = "Age") +
  ylab("Directed Exploration") + 
  xlab("Age") +  
  ylim(0.45,0.85) +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "white", color = NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"), 
        axis.text = element_text(size = 18),
        axis.title = element_text(size = 22),
        plot.title = element_text(size = 24, hjust = 0.5),
        plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines'))
print(direxpl_vs_age)
```


# Information and Reward Analyses
## Mixed Effects Model for Information and Reward Utilization/Prioritization
Investigate the effect of information, reward, trial number, and age on choice number.

Run a mixed-effects linear regression to regress **choice number** in trial against **trial number** in session, the expected **reward** for the chosen tile, the expected **information** for the chosen tile, and **age**. Also, test for all possible interactions. Include intercepts for participants for random effects. 

**Parameters:**
* `Choice_Number`: The choice number in a given trial, where a choice is a selection of a tile on the grid
* `Information`: The expected information for the chosen tile on the given choice, where information is the difference in the entropy, or uncertainty, before and after each choice outcome
* `Reward`: The expected reward for the chosen tile on the given choice, where reward for a given tile is divided by the total number of times that tile had been previously selected
* `Trial`: The trial number at which a choice was made
* `Age`: The age of the participant
* `Subject`: The unique Subject ID for each participant

**Results:**
* As choice number increased, the use of information on tile selection decreased 
* The use of reward on tile selection increased with increasing choice number
* A significant interaction between information and reward was found 
* A significant interaction was also found between trial number and age 
* A three-way interaction was also found between information, reward, and trial number 
* A significant three-way interaction between information, trial number, and age
```{r}
info_rew_mix_mod <- lmerTest::lmer(Choice_Number ~ 1 + Information*Reward*Trial*Age + (1|Subject), data=info_rew_mixed_eff_data, control=lmerControl(optCtrl=list(optimizer='Nelder-Mead',maxfun=2e8)))
summary(info_rew_mix_mod)
confint(info_rew_mix_mod)
```

## Information and Reward Mixed-Effects Model Plot 
### Remove rows where Reward = 0 and run analyses
This model will be used when binning and plotting data below. 
```{r}
# remove rows where reward = 0
info_rew_mixed_eff_data_nz <- info_rew_mixed_eff_data[info_rew_mixed_eff_data$Reward != 0,] # remove rows where Reward = 0

# run 4-way interaction on data with no Reward = 0
# use lmerTest to give df and p-values in the summary as well
info_rew_mix_mod_nz <- lmerTest::lmer(Choice_Number ~ 1 + Information*Reward*Trial*Age + (1|Subject), data=info_rew_mixed_eff_data_nz, control=lmerControl(optCtrl=list(optimizer='Nelder-Mead',maxfun=2e8)))
summary(info_rew_mix_mod_nz)
# mixed-effects model that regresses choice number in trial against information, reward, trial number, and age; finds all interactions between info, reward, age, and trial number
# random slope = none
# random intercept = subject
```


### Binning Raw Data
We first binned ages into the youngest 15 ages (ages 18-33) and the oldest 15 ages (ages 56-71) of participants.
```{r}
# find youngest and oldest participant
min_age <- min(info_rew_mixed_eff_data$Age) #18
max_age <- max(info_rew_mixed_eff_data$Age) #71

# determine bin characteristics
# bin with youngest 15 ages (18-33), this will be all of the original YA sample, since the oldest YA participant is 26
min_participants <- info_rew_mixed_eff_data[info_rew_mixed_eff_data$Age <= 33,]
length(unique(min_participants$Subject)) # 57 subjects in this bin

# bin with oldest 15 ages (56-71)
max_participants <- info_rew_mixed_eff_data[info_rew_mixed_eff_data$Age >= 56,]
length(unique(max_participants$Subject)) # 30 subjects in this bin

# create new dataframes for each bin to work with in the following analyses
# create 4 dataframes total: young bin, young bin without zeroes, old bin, old bin without zeroes
# this is important because when plotting the reward values, we don't want to include reward = 0 rows because there is a disproportionately large number of 0's due to the nature of the task, so this will not allow proper visualization of our findings. # instead, we will want to include 0's for information bins and exclude 0's for reward bins

# young bin df
young_bin_df <- info_rew_mixed_eff_data[info_rew_mixed_eff_data$Age <= 33,]
young_bin_nrz_df <- info_rew_mixed_eff_data[info_rew_mixed_eff_data$Age <= 33 & info_rew_mixed_eff_data$Reward != 0,]

# old bin df
old_bin_df <- info_rew_mixed_eff_data[info_rew_mixed_eff_data$Age >= 56,]
old_bin_nrz_df <- info_rew_mixed_eff_data[info_rew_mixed_eff_data$Age >= 56 & info_rew_mixed_eff_data$Reward != 0,]

```

#### Young Reward Bins 
Next, we binned trial data and reward data in the two age bins.
```{r}
# CREATE UNIQUE TRIAL AND REWARD BINS FOR EACH SUBJECT
# Bin trial numbers by unique Subject
young_bin_nrz_df <- young_bin_nrz_df %>%
  group_by(Subject) %>% # perform the next functions by unique Subject
  mutate(Trial_bin_ranges = cut(Trial, breaks=3)) %>% # create bins (by subject) for trial numbers; will result in a bin range unique to a subject; only leaving this in here as a sanity check to make sure it is going by unique subject id
  mutate(Trial_bins = as.numeric(cut(Trial, breaks=3))) # create a column with the bin ranges replaced with bin number 1, 2, or 3

# Specify the number of reward bins
num_bins <- 5
# Split into bins of equal amounts
young_bin_nrz_df <- young_bin_nrz_df %>%
  mutate(Reward_bins = cut(Reward, breaks = seq(0, 1, length.out = num_bins + 1), labels = FALSE, include.lowest = TRUE))

# FIND AND STORE REWARD BIN PLOT COORDINATES
# Find the average x- (reward) and y-values (choice number) for each subject in each reward bin, in each trial bin
# Place these values in a new table
# Each subject should therefore end up with 15 x-y coordinates, one for each reward bin in each trial bin
tmp_young_bin_nrz_df <- data.frame(matrix(ncol = 5, nrow = 1)) # create temp df to hold data and bind to main df in for loop below
colnames(tmp_young_bin_nrz_df) <- c('Subject', 'Trial_bin', 'Reward_bin', 'X_rew', 'Y_cn') # provide column names
young_rew_bin_coordinates <- data.frame() # create new data frame for YA bin coordinate values; should be 855 rows (check)

for(s in unique(young_bin_nrz_df$Subject)){ # for each unique subject in tmp_young_bin_nrz_df$Subject
  for(t in unique(young_bin_nrz_df$Trial_bins)){  # for each unique trial bin in tmp_young_bin_nrz_df$Trial_bins
    for(r in unique(young_bin_nrz_df$Reward_bins)){  # for each unique reward bin in tmp_young_bin_nrz_df$Reward_bins
      tmp_young_bin_nrz_df$Subject = s # the value to be placed in the 'Subject' column is the value of s during that loop
      tmp_young_bin_nrz_df$Trial_bin = t # the value to be placed in the 'Trial_bin' column is the value of t during that loop
      tmp_young_bin_nrz_df$Reward_bin = r # the value to be placed in the 'Reward_bin' column is the value of r during that loop
      subset_data <- subset(young_bin_nrz_df, Subject == s & Trial_bins == t & Reward_bins == r) # look only at rows in the df where the s, t, and r conditions are met
      tmp_young_bin_nrz_df$X_rew = mean(subset_data$Reward, na.rm=TRUE) # fill the value of 'X_rew' in with the mean of the reward column in the subset data where conditions are met
      tmp_young_bin_nrz_df$Y_cn = mean(subset_data$Choice_Number, na.rm=TRUE) # fill the value of 'Y_cn' in with the mean of the choice number column in the subset data where conditions are met
      young_rew_bin_coordinates = rbind(young_rew_bin_coordinates, tmp_young_bin_nrz_df) # bind the row in the temp df that was created during this iteration of the for loop to the main dataframe; with each loop, a new row will be pasted to the main df
    }
  }
} 

# NORMALIZE REWARD AND CHOICE NUMBER VALUES 
# we need to normalize our reward and choice number data in order to account for within-subject variability 
# removing between-subject variability in the error bars
# https://www.cogsci.nl/blog/tutorials/156-an-easy-way-to-create-graphs-with-within-subject-error-bars 
# the error bars get messed up because the average of reward differs per participant quite a bit
# to remove the between-subject variability, subtract the subject average from each observation, and add the grand average (i.e., the average of all the cells)

# find the "grand average" for reward and choice number 
young_rew_grand_average <- mean(young_bin_nrz_df$Reward, na.rm=TRUE) # 0.6345349
young_cn_grand_average <- mean(young_bin_nrz_df$Choice_Number, na.rm=TRUE) # 4.619752

# find the average reward and choice number values for each subject in the young bin
tmp_sub_rewcn_avg <- data.frame(matrix(ncol = 3, nrow = 1)) # create a temporary df 
colnames(tmp_sub_rewcn_avg) <- c('Subject', 'Avg_rew', 'Avg_cn') # provide column names
young_sub_rewcn_avg <- data.frame() # create new data frame for young bin value averages

# make dataframe with the average X and Y value for each subject in reward bin within each trial bin
for(s in unique(young_bin_nrz_df$Subject)){
  tmp_sub_rewcn_avg$Subject = s
  subset_data <- subset(young_bin_nrz_df, Subject == s)
  tmp_sub_rewcn_avg$Avg_rew = mean(subset_data$Reward, na.rm = TRUE)
  tmp_sub_rewcn_avg$Avg_cn = mean(subset_data$Choice_Number, na.rm = TRUE)
  young_sub_rewcn_avg = rbind(young_sub_rewcn_avg, tmp_sub_rewcn_avg)
}

# add subject averages to young_rew_bin_coordinates df
## reward averages 
young_rew_bin_coordinates$Avg_rew <- NA # make new column

for (i in 1:nrow(young_rew_bin_coordinates)) {
  subject_value <- young_rew_bin_coordinates$Subject[i]
  matching_row <- young_sub_rewcn_avg[young_sub_rewcn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { young_rew_bin_coordinates
    young_rew_bin_coordinates$Avg_rew[i] <- matching_row$Avg_rew
  }
}

## choice number averages
young_rew_bin_coordinates$Avg_cn <- NA # make new column

for (i in 1:nrow(young_rew_bin_coordinates)) {
  subject_value <- young_rew_bin_coordinates$Subject[i]
  matching_row <- young_sub_rewcn_avg[young_sub_rewcn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { young_rew_bin_coordinates
    young_rew_bin_coordinates$Avg_cn[i] <- matching_row$Avg_cn
  }
}

## subtract subject average and add grand average, making a new column for the new normalized reward values 
young_rew_bin_coordinates$norm_rew <- young_rew_bin_coordinates$X_rew - young_rew_bin_coordinates$Avg_rew + young_rew_grand_average
young_rew_bin_coordinates$norm_cn <- young_rew_bin_coordinates$Y_cn - young_rew_bin_coordinates$Avg_cn + young_cn_grand_average


#### now we have normalized coordinates for each participant within each of our bins; let's average that to find the coordinates that we will plot
# take all of the normalized coordinates, and average across subjects per reward bin within each trial bin, resulting in one df containing 15 sets of coordinates to be plotted as the average binned raw data
tmp_avg_rew_pts <- data.frame(matrix(ncol = 4, nrow = 1)) # create temp df
colnames(tmp_avg_rew_pts) <- c('Trial_bin', 'Reward_bin', 'avg_X', 'avg_Y') # provide column names
young_avg_rew_coordinates <- data.frame() # create new data frame for YA reward bin coordinate value averages


# make dataframe with the average X and Y value for each reward bin and each trial; make avg_x and avg_y result from the normalized cn and reward dat
for(t in unique(young_rew_bin_coordinates$Trial_bin)){
  for(r in unique(young_rew_bin_coordinates$Reward_bin)){
    tmp_avg_rew_pts$Trial_bin = t
    tmp_avg_rew_pts$Reward_bin = r
    subset_data <- subset(young_rew_bin_coordinates, Trial_bin == t & Reward_bin == r)
    tmp_avg_rew_pts$avg_X = mean(subset_data$norm_rew, na.rm = TRUE) # using normalized values here
    tmp_avg_rew_pts$avg_Y = mean(subset_data$norm_cn, na.rm = TRUE) # using normalized values here
    young_avg_rew_coordinates = rbind(young_avg_rew_coordinates, tmp_avg_rew_pts)
  }
}
```

#### Old Reward Bins 
Next, we binned trial data and reward data in the two age bins.
```{r}
# CREATE UNIQUE TRIAL AND REWARD BINS FOR EACH SUBJECT
# Bin trial numbers by unique Subject
old_bin_nrz_df <- old_bin_nrz_df %>%
  group_by(Subject) %>% # perform the next functions by unique Subject
  mutate(Trial_bin_ranges = cut(Trial, breaks=3)) %>% # create bins (by subject) for trial numbers; will result in a bin range unique to a subject; only leaving this in here as a sanity check to make sure it is going by unique subject id
  mutate(Trial_bins = as.numeric(cut(Trial, breaks=3))) # create a column with the bin ranges replaced with bin number 1, 2, or 3

# Specify the number of reward bins
num_bins <- 5
# Split into bins of equal amounts
old_bin_nrz_df <- old_bin_nrz_df %>%
  mutate(Reward_bins = cut(Reward, breaks = seq(0, 1, length.out = num_bins + 1), labels = FALSE, include.lowest = TRUE))

# FIND AND STORE REWARD BIN PLOT COORDINATES
# Find the average x- (reward) and y-values (choice number) for each subject in each reward bin, in each trial bin
# Place these values in a new table
# Each subject should therefore end up with 15 x-y coordinates, one for each reward bin in each trial bin
tmp_old_bin_nrz_df <- data.frame(matrix(ncol = 5, nrow = 1)) # create temp df to hold data and bind to main df in for loop below
colnames(tmp_old_bin_nrz_df) <- c('Subject', 'Trial_bin', 'Reward_bin', 'X_rew', 'Y_cn') # provide column names
old_rew_bin_coordinates <- data.frame() # create new data frame for YA bin coordinate values; should be 855 rows (check)

for(s in unique(old_bin_nrz_df$Subject)){ # for each unique subject in tmp_old_bin_nrz_df$Subject
  for(t in unique(old_bin_nrz_df$Trial_bins)){  # for each unique trial bin in tmp_old_bin_nrz_df$Trial_bins
    for(r in unique(old_bin_nrz_df$Reward_bins)){  # for each unique reward bin in tmp_old_bin_nrz_df$Reward_bins
      tmp_old_bin_nrz_df$Subject = s # the value to be placed in the 'Subject' column is the value of s during that loop
      tmp_old_bin_nrz_df$Trial_bin = t # the value to be placed in the 'Trial_bin' column is the value of t during that loop
      tmp_old_bin_nrz_df$Reward_bin = r # the value to be placed in the 'Reward_bin' column is the value of r during that loop
      subset_data <- subset(old_bin_nrz_df, Subject == s & Trial_bins == t & Reward_bins == r) # look only at rows in the df where the s, t, and r conditions are met
      tmp_old_bin_nrz_df$X_rew = mean(subset_data$Reward, na.rm=TRUE) # fill the value of 'X_rew' in with the mean of the reward column in the subset data where conditions are met
      tmp_old_bin_nrz_df$Y_cn = mean(subset_data$Choice_Number, na.rm=TRUE) # fill the value of 'Y_cn' in with the mean of the choice number column in the subset data where conditions are met
      old_rew_bin_coordinates = rbind(old_rew_bin_coordinates, tmp_old_bin_nrz_df) # bind the row in the temp df that was created during this iteration of the for loop to the main dataframe; with each loop, a new row will be pasted to the main df
    }
  }
} 

# NORMALIZE REWARD AND CHOICE NUMBER VALUES 
# we need to normalize our reward and choice number data in order to account for within-subject variability 
# removing between-subject variability in the error bars
# https://www.cogsci.nl/blog/tutorials/156-an-easy-way-to-create-graphs-with-within-subject-error-bars 
# the error bars get messed up because the average of reward differs per participant quite a bit
# to remove the between-subject variability, subtract the subject average from each observation, and add the grand average (i.e., the average of all the cells)

# find the "grand average" for reward and choice number 
old_rew_grand_average <- mean(old_bin_nrz_df$Reward, na.rm=TRUE) # 0.6120188
old_cn_grand_average <- mean(old_bin_nrz_df$Choice_Number, na.rm=TRUE) # 4.880673

# find the average reward and choice number values for each subject in the young bin
tmp_sub_rewcn_avg <- data.frame(matrix(ncol = 3, nrow = 1)) # create a temporary df 
colnames(tmp_sub_rewcn_avg) <- c('Subject', 'Avg_rew', 'Avg_cn') # provide column names
old_sub_rewcn_avg <- data.frame() # create new data frame for young bin value averages

# make dataframe with the average X and Y value for each subject in reward bin within each trial bin
for(s in unique(old_bin_nrz_df$Subject)){
  tmp_sub_rewcn_avg$Subject = s
  subset_data <- subset(old_bin_nrz_df, Subject == s)
  tmp_sub_rewcn_avg$Avg_rew = mean(subset_data$Reward, na.rm = TRUE)
  tmp_sub_rewcn_avg$Avg_cn = mean(subset_data$Choice_Number, na.rm = TRUE)
  old_sub_rewcn_avg = rbind(old_sub_rewcn_avg, tmp_sub_rewcn_avg)
}

# add subject averages to old_rew_bin_coordinates df
## reward averages 
old_rew_bin_coordinates$Avg_rew <- NA # make new column

for (i in 1:nrow(old_rew_bin_coordinates)) {
  subject_value <- old_rew_bin_coordinates$Subject[i]
  matching_row <- old_sub_rewcn_avg[old_sub_rewcn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { old_rew_bin_coordinates
    old_rew_bin_coordinates$Avg_rew[i] <- matching_row$Avg_rew
  }
}

## choice number averages
old_rew_bin_coordinates$Avg_cn <- NA # make new column

for (i in 1:nrow(old_rew_bin_coordinates)) {
  subject_value <- old_rew_bin_coordinates$Subject[i]
  matching_row <- old_sub_rewcn_avg[old_sub_rewcn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { old_rew_bin_coordinates
    old_rew_bin_coordinates$Avg_cn[i] <- matching_row$Avg_cn
  }
}

## subtract subject average and add grand average, making a new column for the new normalized reward values 
old_rew_bin_coordinates$norm_rew <- old_rew_bin_coordinates$X_rew - old_rew_bin_coordinates$Avg_rew + old_rew_grand_average
old_rew_bin_coordinates$norm_cn <- old_rew_bin_coordinates$Y_cn - old_rew_bin_coordinates$Avg_cn + old_cn_grand_average


#### now we have normalized coordinates for each participant within each of our bins; let's average that to find the coordinates that we will plot
# take all of the normalized coordinates, and average across subjects per reward bin within each trial bin, resulting in one df containing 15 sets of coordinates to be plotted as the average binned raw data
tmp_avg_rew_pts <- data.frame(matrix(ncol = 4, nrow = 1)) # create temp df
colnames(tmp_avg_rew_pts) <- c('Trial_bin', 'Reward_bin', 'avg_X', 'avg_Y') # provide column names
old_avg_rew_coordinates <- data.frame() # create new data frame for YA reward bin coordinate value averages


# make dataframe with the average X and Y value for each reward bin and each trial; make avg_x and avg_y result from the normalized cn and reward dat
for(t in unique(old_rew_bin_coordinates$Trial_bin)){
  for(r in unique(old_rew_bin_coordinates$Reward_bin)){
    tmp_avg_rew_pts$Trial_bin = t
    tmp_avg_rew_pts$Reward_bin = r
    subset_data <- subset(old_rew_bin_coordinates, Trial_bin == t & Reward_bin == r)
    tmp_avg_rew_pts$avg_X = mean(subset_data$norm_rew, na.rm = TRUE) # using normalized values here
    tmp_avg_rew_pts$avg_Y = mean(subset_data$norm_cn, na.rm = TRUE) # using normalized values here
    old_avg_rew_coordinates = rbind(old_avg_rew_coordinates, tmp_avg_rew_pts)
  }
}
```

#### Young Information Bins
```{r}
## Bin trial numbers by unique Subject
young_bin_df <- young_bin_df %>%
  group_by(Subject) %>% # perform the next functions by unique Subject
  mutate(Trial_bin_ranges = cut(Trial, breaks=3)) %>% # create bins (by subject) for trial numbers; will result in a bin range unique to a subject; only leaving this in here as a sanity check to make sure it is going by unique subject id
  mutate(Trial_bins = as.numeric(cut(Trial, breaks=3))) # create a column with the bin ranges replaced with bin number 1, 2, or 3

# Information Binning
# Rank information values
young_bin_df <- young_bin_df %>%
  group_by(Subject, Trial_bins) %>% # perform the next functions by unique Subject AND trial_bin
  mutate(Info_ranked = rank(Information)) # rank the reward values for each subject trial bin - by - trial bin

# Specify the number of bins
num_bins <- 5
# YA Information Raw Plot 
# Split into bins of equal amounts
young_bin_df <- young_bin_df %>%
  mutate(Info_bins = cut(Info_ranked, breaks = seq(0, max(Info_ranked), length.out = num_bins + 1), labels = FALSE, include.lowest = TRUE))

# Find the x- (information) and y-values (choice number) for each subject in each information bin, in each trial bin
# INFORMATION COORDINATES: Make new table that holds all x- (information) and y-values (choice number) per bin per subject; for each information bin within each trial bin, each subject should therefore end up with 15 x-y coordinates, one for each information bin in each trial bin
tmp_young_info_bin <- data.frame(matrix(ncol = 5, nrow = 1)) # create temp df to hold data and bind to main df in for loop below
colnames(tmp_young_info_bin) <- c('Subject', 'Trial_bin', 'Info_bin', 'X_info', 'Y_cn') # provide column names
young_info_bin_coordinates <- data.frame() # create new data frame for YA bin coordinate values; should be 855 rows (check)

for(s in unique(young_bin_df$Subject)){ # for each unique subject in tmp_YA_rew_bin_nz$Subject
  for(t in unique(young_bin_df$Trial_bins)){  # for each unique trial bin in tmp_YA_rew_bin_nz$Trial_bins
    for(i in unique(young_bin_df$Info_bins)){  # for each unique reward bin in tmp_YA_rew_bin_nz$Reward_bins
      tmp_young_info_bin$Subject = s # the value to be placed in the 'Subject' column is the value of s during that loop
      tmp_young_info_bin$Trial_bin = t # the value to be placed in the 'Trial_bin' column is the value of t during that loop
      tmp_young_info_bin$Info_bin = i # the value to be placed in the 'Reward_bin' column is the value of r during that loop
      subset_data <- subset(young_bin_df, Subject == s & Trial_bins == t & Info_bins == i) # look only at rows in the df where the s, t, and i conditions are met
      tmp_young_info_bin$X_info = mean(subset_data$Information, na.rm=TRUE) # fill the value of 'X_rew' in with the mean of the reward column in the subset data where conditions are met
      tmp_young_info_bin$Y_cn = mean(subset_data$Choice_Number, na.rm=TRUE) # fill the value of 'Y_cn' in with the mean of the reward column in the subset data where conditions are met
      young_info_bin_coordinates = rbind(young_info_bin_coordinates, tmp_young_info_bin) # bind the row in the temp df that was created during this iteration of the for loop to the main dataframe; with each loop, a new row will be pasted to the main df
    }
  }
}

# NORMALIZE REWARD VALUES AND CHOICE NUMBER VALUES
# we need to normalize our information and choice number data in order to account for within-subject variability 
# removing between-subject variability in the error bars
# https://www.cogsci.nl/blog/tutorials/156-an-easy-way-to-create-graphs-with-within-subject-error-bars 
# the error bars get messed up because the average of information differs per participant quite a bit
# to remove the between-subject variability, subtract the subject average from each observation, and add the grand average (i.e., the average of all the cells)

# find the "grand average" for reward and choice number 
young_info_grand_average <- mean(young_bin_df$Information, na.rm=TRUE) # 0.7732811
young_cn_grand_average <- mean(young_bin_df$Choice_Number, na.rm=TRUE) # 4.841209

# find the average information and choice number values for each subject
tmp_sub_infocn_avg <- data.frame(matrix(ncol = 3, nrow = 1)) # create temp df 
colnames(tmp_sub_infocn_avg) <- c('Subject', 'Avg_info', 'Avg_cn') # provide column names
young_sub_infocn_avg <- data.frame() # create new data frame for young bin value averages

# make dataframe with the average X and Y value for each subject in info bin within each trial bin
for(s in unique(young_bin_df$Subject)){
  tmp_sub_infocn_avg$Subject = s
  subset_data <- subset(young_bin_df, Subject == s)
  tmp_sub_infocn_avg$Avg_info = mean(subset_data$Information, na.rm = TRUE)
  tmp_sub_infocn_avg$Avg_cn = mean(subset_data$Choice_Number, na.rm = TRUE)
  young_sub_infocn_avg = rbind(young_sub_infocn_avg, tmp_sub_infocn_avg)
}

# add subject averages to young_info_bin_coordinates df
# information averages 
young_info_bin_coordinates$Avg_info <- NA # make new column

for (i in 1:nrow(young_info_bin_coordinates)) {
  subject_value <- young_info_bin_coordinates$Subject[i]
  matching_row <- young_sub_infocn_avg[young_sub_infocn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { young_info_bin_coordinates
    young_info_bin_coordinates$Avg_info[i] <- matching_row$Avg_info
  }
}

# choice number averages
young_info_bin_coordinates$Avg_cn <- NA # make new column

for (i in 1:nrow(young_info_bin_coordinates)) {
  subject_value <- young_info_bin_coordinates$Subject[i]
  matching_row <- young_sub_infocn_avg[young_sub_infocn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { young_info_bin_coordinates
    young_info_bin_coordinates$Avg_cn[i] <- matching_row$Avg_cn
  }
}

## subtract subject average and add grand average, making a new column for the new normalized information and cn values 
young_info_bin_coordinates$norm_info <- young_info_bin_coordinates$X_info - young_info_bin_coordinates$Avg_info + young_info_grand_average
young_info_bin_coordinates$norm_cn <- young_info_bin_coordinates$Y_cn - young_info_bin_coordinates$Avg_cn + young_cn_grand_average


#### now we have normalized coordinates for each participant within each of our bins; let's average that to find the coordinates that we will plot
# take all of the normalized coordinates, and average across subjects per information bin within each trial bin, resulting in one df containing 15 sets of coordinates to be plotted as the average binned raw data
tmp_avg_info_pts <- data.frame(matrix(ncol = 4, nrow = 1)) # create temp df
colnames(tmp_avg_info_pts) <- c('Trial_bin', 'Info_bin', 'avg_X', 'avg_Y') # provide column names
young_avg_info_coordinates <- data.frame() # create new data frame for YA reward bin coordinate value averages


# make dataframe with the average X and Y value for each reward bin and each trial; make avg_x and avg_y result from the normalized cn and reward data
for(t in unique(young_info_bin_coordinates$Trial_bin)){
  for(i in unique(young_info_bin_coordinates$Info_bin)){
    tmp_avg_info_pts$Trial_bin = t
    tmp_avg_info_pts$Info_bin = i
    subset_data <- subset(young_info_bin_coordinates, Trial_bin == t & Info_bin == i)
    tmp_avg_info_pts$avg_X = mean(subset_data$norm_info, na.rm = TRUE) # using normalized values here
    tmp_avg_info_pts$avg_Y = mean(subset_data$norm_cn, na.rm = TRUE) # using normalized values here
    young_avg_info_coordinates = rbind(young_avg_info_coordinates, tmp_avg_info_pts)
  }
}

```

#### Old Information Bins
```{r}
## Bin trial numbers by unique Subject
old_bin_df <- old_bin_df %>%
  group_by(Subject) %>% # perform the next functions by unique Subject
  mutate(Trial_bin_ranges = cut(Trial, breaks=3)) %>% # create bins (by subject) for trial numbers; will result in a bin range unique to a subject; only leaving this in here as a sanity check to make sure it is going by unique subject id
  mutate(Trial_bins = as.numeric(cut(Trial, breaks=3))) # create a column with the bin ranges replaced with bin number 1, 2, or 3

## Information Binning
### Rank information values
old_bin_df <- old_bin_df %>%
  group_by(Subject, Trial_bins) %>% # perform the next functions by unique Subject AND trial_bin
  mutate(Info_ranked = rank(Information)) # rank the reward values for each subject trial bin - by - trial bin

### Specify the number of bins
num_bins <- 5
# YA Information Raw Plot 
### Split into bins of equal amounts
old_bin_df <- old_bin_df %>%
  mutate(Info_bins = cut(Info_ranked, breaks = seq(0, max(Info_ranked), length.out = num_bins + 1), labels = FALSE, include.lowest = TRUE))

# Find the x- (information) and y-values (choice number) for each subject in each information bin, in each trial bin
## INFORMATION COORDINATES: Make new table that holds all x- (information) and y-values (choice number) per bin per subject; for each information bin within each trial bin, each subject should therefore end up with 15 x-y coordinates, one for each information bin in each trial bin
tmp_old_info_bin <- data.frame(matrix(ncol = 5, nrow = 1)) # create temp df to hold data and bind to main df in for loop below
colnames(tmp_old_info_bin) <- c('Subject', 'Trial_bin', 'Info_bin', 'X_info', 'Y_cn') # provide column names
old_info_bin_coordinates <- data.frame() # create new data frame for YA bin coordinate values; should be 855 rows (check)

for(s in unique(old_bin_df$Subject)){ # for each unique subject in tmp_YA_rew_bin_nz$Subject
  for(t in unique(old_bin_df$Trial_bins)){  # for each unique trial bin in tmp_YA_rew_bin_nz$Trial_bins
    for(i in unique(old_bin_df$Info_bins)){  # for each unique reward bin in tmp_YA_rew_bin_nz$Reward_bins
      tmp_old_info_bin$Subject = s # the value to be placed in the 'Subject' column is the value of s during that loop
      tmp_old_info_bin$Trial_bin = t # the value to be placed in the 'Trial_bin' column is the value of t during that loop
      tmp_old_info_bin$Info_bin = i # the value to be placed in the 'Reward_bin' column is the value of r during that loop
      subset_data <- subset(old_bin_df, Subject == s & Trial_bins == t & Info_bins == i) # look only at rows in the df where the s, t, and i conditions are met
      tmp_old_info_bin$X_info = mean(subset_data$Information, na.rm=TRUE) # fill the value of 'X_rew' in with the mean of the reward column in the subset data where conditions are met
      tmp_old_info_bin$Y_cn = mean(subset_data$Choice_Number, na.rm=TRUE) # fill the value of 'Y_cn' in with the mean of the reward column in the subset data where conditions are met
      old_info_bin_coordinates = rbind(old_info_bin_coordinates, tmp_old_info_bin) # bind the row in the temp df that was created during this iteration of the for loop to the main dataframe; with each loop, a new row will be pasted to the main df
    }
  }
}

### Normalize reward values and choice number values 
# we need to normalize our information and choice number data in order to account for within-subject variability 
# removing between-subject variability in the error bars
# https://www.cogsci.nl/blog/tutorials/156-an-easy-way-to-create-graphs-with-within-subject-error-bars 
# the error bars get messed up because the average of information differs per participant quite a bit
# to remove the between-subject variability, subtract the subject average from each observation, and add the grand average (i.e., the average of all the cells)

# find the "grand average" for reward and choice number 
old_info_grand_average <- mean(old_bin_df$Information, na.rm=TRUE) # 0.7806684
old_cn_grand_average <- mean(old_bin_df$Choice_Number, na.rm=TRUE) # 4.841209

# find the average information and choice number values for each subject
tmp_sub_infocn_avg <- data.frame(matrix(ncol = 3, nrow = 1)) # create temp df 
colnames(tmp_sub_infocn_avg) <- c('Subject', 'Avg_info', 'Avg_cn') # provide column names
old_sub_infocn_avg <- data.frame() # create new data frame for young bin value averages

# make dataframe with the average X and Y value for each subject in info bin within each trial bin
for(s in unique(old_bin_df$Subject)){
  tmp_sub_infocn_avg$Subject = s
  subset_data <- subset(old_bin_df, Subject == s)
  tmp_sub_infocn_avg$Avg_info = mean(subset_data$Information, na.rm = TRUE)
  tmp_sub_infocn_avg$Avg_cn = mean(subset_data$Choice_Number, na.rm = TRUE)
  old_sub_infocn_avg = rbind(old_sub_infocn_avg, tmp_sub_infocn_avg)
}

# add subject averages to old_info_bin_coordinates df
# information averages 
old_info_bin_coordinates$Avg_info <- NA # make new column

for (i in 1:nrow(old_info_bin_coordinates)) {
  subject_value <- old_info_bin_coordinates$Subject[i]
  matching_row <- old_sub_infocn_avg[old_sub_infocn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { old_info_bin_coordinates
    old_info_bin_coordinates$Avg_info[i] <- matching_row$Avg_info
  }
}

# choice number averages
old_info_bin_coordinates$Avg_cn <- NA # make new column

for (i in 1:nrow(old_info_bin_coordinates)) {
  subject_value <- old_info_bin_coordinates$Subject[i]
  matching_row <- old_sub_infocn_avg[old_sub_infocn_avg$Subject == subject_value, ] 
  if (nrow(matching_row) > 0) { old_info_bin_coordinates
    old_info_bin_coordinates$Avg_cn[i] <- matching_row$Avg_cn
  }
}

## subtract subject average and add grand average, making a new column for the new normalized information and cn values 
old_info_bin_coordinates$norm_info <- old_info_bin_coordinates$X_info - old_info_bin_coordinates$Avg_info + old_info_grand_average
old_info_bin_coordinates$norm_cn <- old_info_bin_coordinates$Y_cn - old_info_bin_coordinates$Avg_cn + old_cn_grand_average


#### now we have normalized coordinates for each participant within each of our bins; let's average that to find the coordinates that we will plot
# take all of the normalized coordinates, and average across subjects per information bin within each trial bin, resulting in one df containing 15 sets of coordinates to be plotted as the average binned raw data
tmp_avg_info_pts <- data.frame(matrix(ncol = 4, nrow = 1)) # create temp df
colnames(tmp_avg_info_pts) <- c('Trial_bin', 'Info_bin', 'avg_X', 'avg_Y') # provide column names
old_avg_info_coordinates <- data.frame() # create new data frame for old information bin coordinate value averages


# make dataframe with the average X and Y value for each reward bin and each trial; make avg_x and avg_y result from the normalized cn and reward data
for(t in unique(old_info_bin_coordinates$Trial_bin)){
  for(i in unique(old_info_bin_coordinates$Info_bin)){
    tmp_avg_info_pts$Trial_bin = t
    tmp_avg_info_pts$Info_bin = i
    subset_data <- subset(old_info_bin_coordinates, Trial_bin == t & Info_bin == i)
    tmp_avg_info_pts$avg_X = mean(subset_data$norm_info, na.rm = TRUE) # using normalized values here
    tmp_avg_info_pts$avg_Y = mean(subset_data$norm_cn, na.rm = TRUE) # using normalized values here
    old_avg_info_coordinates = rbind(old_avg_info_coordinates, tmp_avg_info_pts)
  }
}
```


### Plotting the Binned Data
#### Young Reward Plot
```{r}
# Plot Young Reward Data
### Plotting
# order reward bins in ascending order (important for plot)
young_avg_rew_coordinates <- young_avg_rew_coordinates %>% arrange(Reward_bin)

# plot average coordinates for young adults 
## change default colors for the plots to match the model plot
colors <- c("#E41818", "#26BC32", "#2A8FFC")
factor_levels <- unique(young_avg_rew_coordinates$Trial_bin)
## make the plot
plot(young_avg_rew_coordinates$avg_X, young_avg_rew_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.0), ylim = c(-2,13))
# connect points with lines
for (level in factor_levels) {
  subset_data <- young_avg_rew_coordinates[young_avg_rew_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

# using SE for error bars
# Loop through factor levels again to draw error bars
plot(young_avg_rew_coordinates$avg_X, young_avg_rew_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.0), ylim = c(-2,13))

# connect points with lines
for (level in factor_levels) {
  subset_data <- young_avg_rew_coordinates[young_avg_rew_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

for (level in factor_levels) {
  subset_data <- young_avg_rew_coordinates[young_avg_rew_coordinates$Trial_bin == level, ]

  # Calculate standard error of the mean
  se_values <- sd(subset_data$avg_Y) / sqrt(length(subset_data$avg_Y))

  # Draw error bars using arrows
  arrows(
    subset_data$avg_X,
    subset_data$avg_Y - se_values,
    subset_data$avg_X,
    subset_data$avg_Y + se_values,
    angle = 90, code = 3, length = 0.1, col = colors[level]
  )
}

young_rew_raw_plot <- recordPlot

```

#### Old Reward Plot
```{r} 
# Plot Young Reward Data
### Plotting
# order reward bins in ascending order (important for plot)
old_avg_rew_coordinates <- old_avg_rew_coordinates %>% arrange(Reward_bin)

# plot average coordinates for young adults 
## change default colors for the plots to match the model plot
colors <- c("#E41818", "#26BC32", "#2A8FFC")
factor_levels <- unique(old_avg_rew_coordinates$Trial_bin)
## make the plot
plot(old_avg_rew_coordinates$avg_X, old_avg_rew_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.0), ylim = c(-2,13))
# connect points with lines
for (level in factor_levels) {
  subset_data <- old_avg_rew_coordinates[old_avg_rew_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

# using SE for error bars
# Loop through factor levels again to draw error bars
plot(old_avg_rew_coordinates$avg_X, old_avg_rew_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.0), ylim = c(-2,13))

# connect points with lines
for (level in factor_levels) {
  subset_data <- old_avg_rew_coordinates[old_avg_rew_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

for (level in factor_levels) {
  subset_data <- old_avg_rew_coordinates[old_avg_rew_coordinates$Trial_bin == level, ]

  # Calculate standard error of the mean
  se_values <- sd(subset_data$avg_Y) / sqrt(length(subset_data$avg_Y))

  # Draw error bars using arrows
  arrows(
    subset_data$avg_X,
    subset_data$avg_Y - se_values,
    subset_data$avg_X,
    subset_data$avg_Y + se_values,
    angle = 90, code = 3, length = 0.1, col = colors[level]
  )
}

old_rew_raw_plot <- recordPlot

```

#### Young Information Plot 
```{r}
young_avg_info_coordinates <- young_avg_info_coordinates %>% arrange(Info_bin)

# plot average coordinates for young adults 
## change default colors for the plots to match the model plot
colors <- c("#E41818", "#26BC32", "#2A8FFC")
factor_levels <- unique(young_avg_info_coordinates$Trial_bin)
## make the plot
plot(young_avg_info_coordinates$avg_X, young_avg_info_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.5), ylim = c(-2,13))
# connect points with lines
for (level in factor_levels) {
  subset_data <- young_avg_info_coordinates[young_avg_info_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

# using SE for error bars
# Loop through factor levels again to draw error bars
plot(young_avg_info_coordinates$avg_X, young_avg_info_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.5), ylim = c(-2,13))

# connect points with lines
for (level in factor_levels) {
  subset_data <- young_avg_info_coordinates[young_avg_info_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

for (level in factor_levels) {
  subset_data <- young_avg_info_coordinates[young_avg_info_coordinates$Trial_bin == level, ]

  # Calculate standard error of the mean
  se_values <- sd(subset_data$avg_Y) / sqrt(length(subset_data$avg_Y))

  # Draw error bars using arrows
  arrows(
    subset_data$avg_X,
    subset_data$avg_Y - se_values,
    subset_data$avg_X,
    subset_data$avg_Y + se_values,
    angle = 90, code = 3, length = 0.1, col = colors[level]
  )
}

young_info_raw_plot <- recordPlot()

```
#### Old Information Plot 
```{r}
old_avg_info_coordinates <- old_avg_info_coordinates %>% arrange(Info_bin)

# plot average coordinates for young adults 
## change default colors for the plots to match the model plot
colors <- c("#E41818", "#26BC32", "#2A8FFC")
factor_levels <- unique(old_avg_info_coordinates$Trial_bin)
## make the plot
plot(old_avg_info_coordinates$avg_X, old_avg_info_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.5), ylim = c(-2,13))
# connect points with lines
for (level in factor_levels) {
  subset_data <- old_avg_info_coordinates[old_avg_info_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

# using SE for error bars
# Loop through factor levels again to draw error bars
plot(old_avg_info_coordinates$avg_X, old_avg_info_coordinates$avg_Y, type = "n", xlim = c(-0.01,1.5), ylim = c(-2,13))

# connect points with lines
for (level in factor_levels) {
  subset_data <- old_avg_info_coordinates[old_avg_info_coordinates$Trial_bin == level, ]
  points(subset_data$avg_X, subset_data$avg_Y, pch = 19, col = colors[level])
  lines(subset_data$avg_X, subset_data$avg_Y, type = "b", col = colors[level])
}

for (level in factor_levels) {
  subset_data <- old_avg_info_coordinates[old_avg_info_coordinates$Trial_bin == level, ]

  # Calculate standard error of the mean
  se_values <- sd(subset_data$avg_Y) / sqrt(length(subset_data$avg_Y))

  # Draw error bars using arrows
  arrows(
    subset_data$avg_X,
    subset_data$avg_Y - se_values,
    subset_data$avg_X,
    subset_data$avg_Y + se_values,
    angle = 90, code = 3, length = 0.1, col = colors[level]
  )
}

old_info_raw_plot <- recordPlot()

```

### Find marginal effects slopes and plot with binned data
Next, we found the marginal effects of information/reward, age, and trial number on choice number from the mixed-effects model to provide regression lines atop the binned raw data found above. 
```{r}
# transform trial columns into numeric class for mean calculations
young_bin_df$Trial <- as.numeric(young_bin_df$Trial)
old_bin_df$Trial <- as.numeric(old_bin_df$Trial)
young_bin_nrz_df$Trial <- as.numeric(young_bin_nrz_df$Trial)
old_bin_nrz_df$Trial <- as.numeric(old_bin_nrz_df$Trial)

# find average trials for each bin
# we will need these to plot the marginal effects for each bin. within each trial bin, we want to find the marginal effect. to do this, we find the average trial number within each trial bin and make that the trial value when finding the marginal effects
# Young information
young_info_tbin1_mean <- mean(young_bin_df$Trial[young_bin_df$Trial_bins == 1], na.rm = TRUE)
young_info_tbin2_mean <- mean(young_bin_df$Trial[young_bin_df$Trial_bins == 2], na.rm = TRUE)
young_info_tbin3_mean <- mean(young_bin_df$Trial[young_bin_df$Trial_bins == 3], na.rm = TRUE)

# Old information
old_info_tbin1_mean <- mean(old_bin_df$Trial[old_bin_df$Trial_bins == 1], na.rm = TRUE)
old_info_tbin2_mean <- mean(old_bin_df$Trial[old_bin_df$Trial_bins == 2], na.rm = TRUE)
old_info_tbin3_mean <- mean(old_bin_df$Trial[old_bin_df$Trial_bins == 3], na.rm = TRUE)

# Young reward
young_rew_tbin1_mean <- mean(young_bin_nrz_df$Trial[young_bin_nrz_df$Trial_bins == 1], na.rm = TRUE)
young_rew_tbin2_mean <- mean(young_bin_nrz_df$Trial[young_bin_nrz_df$Trial_bins == 2], na.rm = TRUE)
young_rew_tbin3_mean <- mean(young_bin_nrz_df$Trial[young_bin_nrz_df$Trial_bins == 3], na.rm = TRUE)

# Old reward
old_rew_tbin1_mean <- mean(old_bin_nrz_df$Trial[old_bin_nrz_df$Trial_bins == 1], na.rm = TRUE)
old_rew_tbin2_mean <- mean(old_bin_nrz_df$Trial[old_bin_nrz_df$Trial_bins == 2], na.rm = TRUE)
old_rew_tbin3_mean <- mean(old_bin_nrz_df$Trial[old_bin_nrz_df$Trial_bins == 3], na.rm = TRUE)

# find marginal effects for each of the 12 lines
# Young information
young_info_meffects_t1 <- ggpredict(info_rew_mix_mod, c("Information", "Age[18:33]", "Trial[young_info_tbin1_mean]"))
young_info_meffects_t2 <- ggpredict(info_rew_mix_mod, c("Information", "Age[18:33]", "Trial[young_info_tbin2_mean]"))
young_info_meffects_t3 <- ggpredict(info_rew_mix_mod, c("Information", "Age[18:33]", "Trial[young_info_tbin3_mean]"))

# Old information
old_info_meffects_t1 <- ggpredict(info_rew_mix_mod, c("Information", "Age[56:71]", "Trial[old_info_tbin1_mean]"))
old_info_meffects_t2 <- ggpredict(info_rew_mix_mod, c("Information", "Age[56:71]", "Trial[old_info_tbin2_mean]"))
old_info_meffects_t3 <- ggpredict(info_rew_mix_mod, c("Information", "Age[56:71]", "Trial[old_info_tbin3_mean]"))

# Young reward
young_rew_meffects_t1 <- ggpredict(info_rew_mix_mod_nz, c("Reward", "Age[18:33]", "Trial[young_rew_tbin1_mean]"))
young_rew_meffects_t2 <- ggpredict(info_rew_mix_mod_nz, c("Reward", "Age[18:33]", "Trial[young_rew_tbin2_mean]"))
young_rew_meffects_t3 <- ggpredict(info_rew_mix_mod_nz, c("Reward", "Age[18:33]", "Trial[young_rew_tbin3_mean]"))

# Old reward
old_rew_meffects_t1 <- ggpredict(info_rew_mix_mod_nz, c("Reward", "Age[56:71]", "Trial[old_rew_tbin1_mean]"))
old_rew_meffects_t2 <- ggpredict(info_rew_mix_mod_nz, c("Reward", "Age[56:71]", "Trial[old_rew_tbin2_mean]"))
old_rew_meffects_t3 <- ggpredict(info_rew_mix_mod_nz, c("Reward", "Age[56:71]", "Trial[old_rew_tbin3_mean]"))

```


### Make combined plot
Next, we took our binned raw data points and overlapped the regression lines on top of them for best visualization of the mixed effects model results.
```{r}
# set theme for all plots 
set_theme(
  base = theme_classic()
)

# Young Information
young_avg_info_coordinates$Trial_bin <- as.factor(young_avg_info_coordinates$Trial_bin)
young_info_comb_plot <- ggplot(young_avg_info_coordinates, aes(x = avg_X, y = avg_Y, color = factor(Trial_bin))) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), guide = "legend", labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01) + # Adjust position if needed
  geom_smooth(data = young_info_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_info_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_info_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Young Age Bin") + # add title
  labs(subtitle = "Ages 18-33") +
  xlim(0.43,1.2) +
  ylim(0,10) +
  ylab("Choice Number") + # add y-axis label
  xlab("Information") + # add x-axis label
  theme(panel.grid.major = element_blank()) +  # Remove major grid lines
  theme(panel.grid.minor = element_blank()) +
  theme(axis.text = element_text(size = 14)) + 
  theme(axis.title = element_text(size = 16)) +
  theme(plot.subtitle = element_text(size = 16)) +
  theme(plot.title = element_text(size = 18)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5)) +
  theme(legend.text = element_text(size = 14)) +
  theme(plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines')) +
  theme(legend.position = "bottom") +
  theme(legend.justification = "center") +
  theme(legend.title= element_blank())
young_info_comb_plot  

# OA Information
old_avg_info_coordinates$Trial_bin <- as.factor(old_avg_info_coordinates$Trial_bin)
old_info_comb_plot <- ggplot(old_avg_info_coordinates, aes(x = avg_X, y = avg_Y, color = factor(Trial_bin))) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), guide = "legend", labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01, position = position_dodge(0.5)) + # Adjust position if needed
  geom_smooth(data = old_info_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_info_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_info_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Old Age Bin") + # add title  
  labs(subtitle = "Ages 56-71") +
  xlim(0.43,1.2) +
  ylim(0,10) +
  ylab("Choice Number") + # add y-axis label
  xlab("Information") + # add x-axis label
  theme(panel.grid.major = element_blank()) +  # Remove major grid lines
  theme(panel.grid.minor = element_blank()) +
  theme(axis.text = element_text(size = 14)) + 
  theme(axis.title = element_text(size = 16)) +
  theme(plot.subtitle = element_text(size = 16)) +
  theme(plot.title = element_text(size = 18)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5)) +
  theme(legend.text = element_text(size = 14)) +
  theme(plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines')) +
  theme(legend.position = "bottom") +
  theme(legend.justification = "center") +
  theme(legend.title= element_blank())
old_info_comb_plot  


# YA Reward
young_avg_rew_coordinates$Trial_bin <- as.factor(young_avg_rew_coordinates$Trial_bin)
young_rew_comb_plot <- ggplot(young_avg_rew_coordinates, aes(x = avg_X, y = avg_Y, color = factor(Trial_bin))) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), guide = "legend", labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01, position = position_dodge(0.5)) + # Adjust position if needed
  geom_smooth(data = young_rew_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_rew_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = young_rew_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Young Age Bin") + # add title
  labs(subtitle = "Ages 18-33") +
  xlim(0,1.1) +
  ylim(0,7.5) +
  ylab("Choice Number") + # add y-axis label
  xlab("Reward") + # add x-axis label
  theme(panel.grid.major = element_blank()) +  # Remove major grid lines
  theme(panel.grid.minor = element_blank()) +
  theme(axis.text = element_text(size = 14)) + 
  theme(axis.title = element_text(size = 16)) +
  theme(plot.subtitle = element_text(size = 16)) +
  theme(plot.title = element_text(size = 18)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5)) +
  theme(legend.text = element_text(size = 14)) +
  theme(plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines')) +
  theme(legend.position = "bottom") +
  theme(legend.justification = "center") +
  theme(legend.title= element_blank())
young_rew_comb_plot 

# OA Reward
old_avg_rew_coordinates$Trial_bin <- as.factor(old_avg_rew_coordinates$Trial_bin)
old_rew_comb_plot <- ggplot(old_avg_rew_coordinates, aes(x = avg_X, y = avg_Y, color = factor(Trial_bin)), xlim = c(0, 1.1), ylim = c(0, 13)) +
  geom_point(show.legend = FALSE, size = 2) +
  scale_color_manual(values=c("#E41818", "#26BC32", "#2A8FFC"), guide = "legend", labels = c("Early Trials", "Middle Trials", "Late Trials")) +
  geom_errorbar(aes(ymin = avg_Y - sd(avg_Y) / sqrt(length(avg_Y)), ymax = avg_Y + sd(avg_Y) / sqrt(length(avg_Y))), width = 0.01, position = position_dodge(0.5)) + # Adjust position if needed
  geom_smooth(data = old_rew_meffects_t1, aes(x = x, y = predicted), method = "lm", color = "#E41818", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_rew_meffects_t2, aes(x = x, y = predicted), method = "lm", color = "#26BC32", size = 1, fullrange = TRUE) +
  geom_smooth(data = old_rew_meffects_t3, aes(x = x, y = predicted), method = "lm", color = "#2A8FFC", size = 1, fullrange = TRUE) +
  ggtitle("Old Age Bin") + # add title
  labs(subtitle = "Ages 56-71") +
  xlim(0,1.1) +
  ylim(0,7.5) +
  ylab("Choice Number") + # add y-axis label
  xlab("Reward") + # add x-axis label
  theme(panel.grid.major = element_blank()) +  # Remove major grid lines
  theme(panel.grid.minor = element_blank()) +
  theme(axis.text = element_text(size = 14)) + 
  theme(axis.title = element_text(size = 16)) +
  theme(plot.subtitle = element_text(size = 16)) +
  theme(plot.title = element_text(size = 18)) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5)) +
  theme(legend.text = element_text(size = 14)) +
  theme(plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines')) +
  theme(legend.position = "bottom") +
  theme(legend.justification = "center") +
  theme(legend.title= element_blank())
old_rew_comb_plot  

cn_inforew_comb <- ggarrange(young_rew_comb_plot, old_rew_comb_plot, young_info_comb_plot, old_info_comb_plot, ncol = 2, nrow = 2, common.legend = TRUE, legend = "bottom", labels = c("A", "B", "C", "D"), font.label = list(size = 16))

#cn_inforew_comb <- cn_inforew_comb +
 # theme(legend.position = "bottom", legend.justification = "center", legend.box = "horizontal")

print(cn_inforew_comb)

```

## Relationship Beween Information and Reward
Run a mixed-effects linear regression to regress **information** against **reward**. Include intercepts for subjects for random effects. 

**Parameters:**
* `Information`: The expected information for the chosen tile on the given choice, where information is the difference in the entropy, or uncertainty, before and after each choice outcome
* `Reward`: The expected reward for the chosen tile on the given choice, where reward for a given tile is the number of of times choosing that tile revealed a portion of the shape (hits) in the past divided by the total number of times that tile had been previously selected
* `Subject`: The unique Subject ID for each participant
             
**Results:**
* Information and reward are negatively correlated (β = -0.021, 95% CI [-0.032, -0.009], p < 0.001).
```{r}
rew_info_rel_model=lmer(Information ~ Reward + (Reward|Subject), data=info_rew_mixed_eff_data)
summary(rew_info_rel_model)
confint(rew_info_rel_model)
```

## Information and Reward Relationship as Trials Progress
Run a mixed-effects linear regression to regress **information** against **reward** and **trial number** as well as the **reward X trial number** interaction. Include intercepts for subjects for random effects. 

**Parameters:**
* `Information`: The expected information for the chosen tile on the given choice, where information is the difference in the entropy, or uncertainty, before and after each choice outcome
* `Reward`: The expected reward for the chosen tile on the given choice, where reward for a given tile is the number of of times choosing that tile revealed a portion of the shape (hits) in the past divided by the total number of times that tile had been previously selected
* `Trial`: The trial number at which a choice was made
* `Subject`: The unique Subject ID for each participant

**Results:**
* Information and reward become more negatively correlated as trial number increases (β = -3.069 x 10-3, 95% CI [-3.762 x 10-3, -2.375 x 10-3], p < 0.0001)
```{r}
rew_info_trial_rel_model=lmer(Information ~ Reward*Trial + (Reward*Trial|Subject), data=info_rew_mixed_eff_data)
summary(rew_info_trial_rel_model)
confint(rew_info_trial_rel_model)
```


# Foraging Abilities and Learning Analyses
## Information Forager Score and Reward Forager Score 
Run Pearson correlation test to test the relationship between **information forager score** and **reward forager score**

**Parameters:**
* `info_fs`: The information forager score
* `rew_fs`: The reward forager score

**Results:**
*  Information forager scores and reward forager scores are significantly anticorrelated (r = -0.629, p < 0.001) 
```{r}
cor.test(forscore_cpt_data$info_fs, forscore_cpt_data$rew_fs, method = "pearson")
```


## Age and Information Forager Score
Run a linear regression to regress **information forager score** against **age** of participant

**Parameters:**
* `info_fs`: The information forager score for a given participant
* `age`: The age of the participant

**Results:**
* Older age is associated with higher information forager scores (β = 0.003 ± 0.0008, p < 0.001) 
```{r}
age_info_fs_mod <- lm(info_fs ~ age, data = forscore_cpt_data)
summary(age_info_fs_mod)
```


## Age and Reward Forager Score
Run a linear regression to regress **reward forager score** against **age** of the participant

**Parameters:**
* `rew_fs`: The reward forager score for a given participant
* `age`: The age of the participant

**Results:**
* Older age is associated with lower reward forager scores (β = -0.001 ± 0.0004, p < 0.001).
```{r}
age_rew_fs_mod <- lm(rew_fs ~ age, data = forscore_cpt_data)
summary(age_rew_fs_mod)
```


## Information Forager Score and Final Changepoint
Run a linear regression to regress **changepoint** against **information forager score** and **age** of the participant, along with the **information forager score X age** interaction. 

**Parameters:**
* `changepoint`: The trial number at which the changepoint detection test detected learning of the shape set. Lower changepoint indicates a sooner trial and thus indicates faster learning
* `info_fs`: The information forager score for a given participant
* `age`: The age of the participant

**Results:**
* The ability to forage for information was associated with a lower changepoint (β = -63.149, 95% CI [-107.744, -18.553], p = 0.006)
* In other words, the ability to forage for information is associated with faster learning
* There was no main effect of age or interaction between age and information forager score
```{r}
info_fs_cpt_age <- lm(changepoint ~ info_fs + age + info_fs:age, data=forscore_cpt_data)
summary(info_fs_cpt_age)
confint(info_fs_cpt_age)
```


## Reward Forager Score and Final Changepoint
Run a linear regression to regress **changepoint** against **reward forager score** and **age** of the participant, along with the **reward forager score X age** interaction. 

**Parameters:**
* `changepoint`: The trial number at which the changepoint detection test detected learning of the shape set. Lower changepoint indicates a sooner trial and thus indicates faster learning
* `rew_fs`: The reward forager score for a given participant
* `age`: The age of the participant

**Results:**
* The ability to forage for reward was associated with a higher changepoint (β = 127.684, 95% CI [16.278, 239.089], p = 0.025)
* In other words, the ability to forage for reward is associated with slower learning
* There was no main effect of age or interaction between age and reward forager score
```{r}
rew_fs_cpt_age <- lm(changepoint ~ rew_fs + age + rew_fs:age, data=forscore_cpt_data)
summary(rew_fs_cpt_age)
confint(rew_fs_cpt_age)
```

## Plot Forager Scores vs. Changepoint by Age
```{r}
# perform relevant calculations to be used in below plots 
# perform information linear regressions based on age 
lm_fit_i_cpt <- lm(changepoint ~ info_fs, data=forscore_cpt_data)
lm_fit_r_cpt <- lm(changepoint ~ rew_fs, data=forscore_cpt_data)

# define custom functions to restrict the rlm regression line to a certain x-range in the plot
# information custom function
i_function <- function(x) {
  if (min(forscore_cpt_data$info_fs) < x & x < max(forscore_cpt_data$info_fs)) {
    intercept <- lm_fit_i_cpt$coefficients[1]
    slope <- lm_fit_i_cpt$coefficients[2]
    y <- intercept + slope * x
    return(y)
  } else {
    return(NA)
  }
}

# reward custom function 
r_function <- function(x) {
  if (min(forscore_cpt_data$rew_fs) < x & x < max(forscore_cpt_data$rew_fs)) {
    intercept <- lm_fit_r_cpt$coefficients[1]
    slope <- lm_fit_r_cpt$coefficients[2]
    y <- intercept + slope * x
    return(y)
  } else {
    return(NA)
  }
}

# get mean and sd cpts 
mean_cpts <- mean(totals_df$cpt, na.rm = TRUE) 
sd_cpts <- sd(totals_df$cpt, na.rm = TRUE) 

# changepoint vs. information foraging
cpts_vs_ifs <- ggplot(forscore_cpt_data, aes(info_fs, changepoint)) +
  geom_point(aes(color = age)) +
  scale_color_gradient(low = "#0B72F7", high = "#F70B0B") + # customized color palette
  stat_smooth(linetype = 0, mapping = NULL, data = NULL, geom = "smooth", position = "identity",   method = "lm", formula = NULL, se = TRUE, n = 80, span = 0.75, fullrange =    
  FALSE, level = 0.95, method.args = list(), na.rm = FALSE, orientation = NA, 
  show.legend = NA, inherit.aes = TRUE) +
  geom_function(fun=Vectorize(i_function), linewidth = 1) +
  labs(color = "Age") +
  scale_x_continuous(breaks = seq(0, 1.0, by = 0.2), limits = c(0.08, 1.0)) +
  scale_y_continuous(limits = c(0, 90)) +
  ylab("Final Changepoint") + # add y-axis label
  xlab("Information Foraging Score") + # add x-axis label 
  theme_minimal() +
  theme(panel.background = element_rect(fill = "white", color = NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"), 
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 16),
        plot.title = element_text(size = 20, hjust = 0.5),
        plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines'),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 16),
        legend.position = "none") +
  guides(color = guide_colorbar(barwidth = 18, barheight = 1))  # Adjust the size of the color bar
cpts_vs_ifs

# changepoint vs. reward foraging
cpts_vs_rfs <- ggplot(forscore_cpt_data, aes(rew_fs, changepoint)) +
  geom_point(aes(color = age)) +
  scale_color_gradient(low = "#0B72F7", high = "#F70B0B") + # customized color palette
  stat_smooth(linetype = 0, mapping = NULL, data = NULL, geom = "smooth", position = "identity",   method = "lm", formula = NULL, se = TRUE, n = 80, span = 0.75, fullrange =    
  TRUE, level = 0.95, method.args = list(), na.rm = FALSE, orientation = NA, 
  show.legend = NA, inherit.aes = TRUE) +
  geom_function(fun=Vectorize(r_function), linewidth = 1) +
  labs(color = "Age") +
  scale_x_continuous(breaks = seq(0, 1.0, by = 0.2), limits = c(0.08, 1.0)) +
  scale_y_continuous(limits = c(0, 90)) +
  ylab("Final Changepoint") + # add y-axis label
  xlab("Reward Foraging Score") + # add x-axis label 
  theme_minimal() +
  theme(panel.background = element_rect(fill = "white", color = NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"), 
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 16),
        plot.title = element_text(size = 20, hjust = 0.5),
        plot.margin = unit(c(1.4,1.4,1.4,1.4), 'lines'),
        legend.text = element_text(size = 14),
        legend.title = element_text(size = 16),
        legend.position = "none") +
  guides(color = guide_colorbar(barwidth = 18, barheight = 1))  # Adjust the size of the color bar
cpts_vs_rfs

# Combine plots
both_cpts_vs_fs <- ggarrange(cpts_vs_ifs, cpts_vs_rfs,ncol = 2, nrow = 1, common.legend = TRUE, legend = "bottom", labels = c("A", "B"), font.label = list(size = 19))
both_cpts_vs_fs
```


# Mediation Analysis
Run a mediation analysis to investigate whether information forager score mediates the relationship between age and final changepoint, using the “mediation” R software package (Tingley et al., 2014).

## Mediator Model: Regress the mediator on the independent variable.
**Parameters:**
* `info_fs`: The information forager score for a given participant (mediator)
* `age`: The age of the participant (independent variable)

**Results:**
* Age is positively associated with the information forager score
```{r}
mediator_mod <- lm(info_fs ~ age, data = info_rew_means_cpt_fs)
print(summary(mediator_mod))
confint(mediator_mod)
```

## Outcome Model: Regress the dependent variable on both the independent variable and the mediator.
**Parameters:**
* `changepoint`: The trial number at which the changepoint detection test detected learning of the shape set. Lower changepoint indicates a sooner trial and thus indicates faster learning (dependent variable)
* `info_fs`: The information forager score for a given participant (mediator)
* `age`: The age of the participant (independent variable)

**Results:**
* The direct effect of age on changepoint is negative but *not* statistically significant.
* Information forager score is strongly and negatively associated with changepoint. In other words, higher information forager scores are linked to lower changepoints (faster learning).
```{r}
# outcome model
outcome_mod <- lm(changepoint ~ age + info_fs, data = info_rew_means_cpt_fs)
print(summary(outcome_mod))
confint(outcome_mod)
```

## Mediation Analysis Model

**Parameters:**
* `model.m`: The **mediator model** (`mediator_mod`) predicting info_fs from age
* `model.y`: The **outcome model** (`outcome_mod`) predicting changepoint from age and info_fs
* `treat`: Treatment variable (`age`)
* `mediator`: Mediator variable (`info_fs`)
* `boot`: Logical flag indicating whether to use bootstrapping for confidence intervals (`TRUE`)
* `sims`: Number of bootstrap simulations (`10000`)

**Path Relationships Estimated:**
* **Direct effect (`ADE`):** Effect of age on changepoint not explained by info_fs
* **Indirect effect (`ACME`):** Effect of age on changepoint transmitted through info_fs
* **Total effect:** Combined direct and indirect effects of age on changepoint

**Mediation Analysis Results:**
* The total effect of age on final changepoint was significant, with increasing age associated with a lower final changepoint, as previously discussed. See `Total Effect` in below analyses.
* Mediation analysis revealed a significant indirect effect of age on changepoint through information forager score (β = -0.201, 95% CI [-0.3163, -0.09], p < 0.001), indicating that information forager score, at least partially, explains the relationship between age and final changepoint. See `ACME` in below analyses.
* After controlling for information forager score, the direct effect of age on final changepoint was attenuated, consistent with a complete mediation. See `ADE` in below analyses.
* Information forager score mediated approximately 75.25% of the total effect (95% CI [39.51, 203], p = 0.003), suggesting that a substantial portion of the association between age and changepoint operates through differences in information-seeking strategies. See `Prop. Mediated` in below analyses.
```{r}
info_age_fs_med <- mediate(
  model.m = mediator_mod,
  model.y = outcome_mod,
  treat = "age",
  mediator = "info_fs",
  boot = TRUE, # bootstrapping for more robust CIs
  sims = 10000 # number of simulations for bootstrap
)
# sample size used: 154 
print(summary(info_age_fs_med))
```
